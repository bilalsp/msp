{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Modules: Datasets and Graphs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from msp.datasets import make_data, load_sample_data, make_sparse_data\n",
    "from msp.graphs import MSPGraph, MSPSparseGraph\n",
    "from msp.models.encoders import GGCNEncoder\n",
    "from msp.models.decoders import AttentionDecoder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_sparse_data(40, msp_size=(1,2), random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSPSparseGraph(adj_matrix=<tf.Tensor: shape=(2, 3, 3), dtype=uint8, numpy=\n",
       "array([[[0, 1, 1],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0]],\n",
       "\n",
       "       [[0, 1, 1],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0]]], dtype=uint8)>, node_features=<tf.Tensor: shape=(2, 3, 5), dtype=float64, numpy=\n",
       "array([[[0.60597828, 0.73336936, 0.13894716, 0.31267308, 1.        ],\n",
       "        [0.12816238, 0.17899311, 0.75292543, 0.66216051, 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.82309863, 0.73222503, 0.06905627, 0.67212894, 1.        ],\n",
       "        [0.82801437, 0.20446939, 0.61748895, 0.61770101, 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]])>, edge_features=<tf.Tensor: shape=(2, 3, 3, 3), dtype=float64, numpy=\n",
       "array([[[[0.        , 0.        , 0.        ],\n",
       "         [0.57430428, 0.37116084, 0.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.57430428, 0.37116084, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.70901567, 0.8906554 , 0.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.70901567, 0.8906554 , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ]]]])>, alpha=<tf.Tensor: shape=(2, 3, 1), dtype=float64, numpy=\n",
       "array([[[1.],\n",
       "        [1.],\n",
       "        [0.]],\n",
       "\n",
       "       [[1.],\n",
       "        [1.],\n",
       "        [0.]]])>)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "batch_size = 2\n",
    "batch_dataset = dataset.batch(batch_size)\n",
    "inputs = list(batch_dataset.take(1))[0]\n",
    "inputs"
   ]
  },
  {
   "source": [
    "# Modules: Layers and Encoders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 6\n",
    "layers = 2\n",
    "ecoder_model = GGCNEncoder(units, layers)\n",
    "embedded_inputs = ecoder_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 6), dtype=float32, numpy=\n",
       "array([[[ 0.615415  ,  1.2802217 ,  0.99935806, -0.5541735 ,\n",
       "          3.416307  ,  1.355025  ],\n",
       "        [ 1.1635169 , -0.16933191,  0.7606487 , -0.3814553 ,\n",
       "          1.1589245 ,  0.81719756],\n",
       "        [ 0.        ,  0.01952665,  0.        ,  0.        ,\n",
       "          0.43814158,  1.0351074 ]],\n",
       "\n",
       "       [[ 0.832458  ,  0.50137305,  1.155561  , -0.44193715,\n",
       "          3.733396  ,  1.3800619 ],\n",
       "        [ 1.3427941 , -0.11154047,  1.1022799 , -0.15452659,\n",
       "          2.8134623 ,  0.7567066 ],\n",
       "        [ 0.04526918,  0.        ,  0.        ,  0.        ,\n",
       "          0.7266619 ,  0.9510701 ]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "embedded_inputs.node_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3, 6), dtype=float32, numpy=\n",
       "array([[[[ 1.46499956e+00,  5.61989486e-01,  0.00000000e+00,\n",
       "           8.34677815e-01,  1.68942082e+00,  3.30655384e+00],\n",
       "         [ 5.46871126e-03,  8.56781602e-01, -8.03075433e-02,\n",
       "           8.83548975e-01,  1.39451098e+00,  2.42211223e+00],\n",
       "         [-1.17827654e-01,  1.21429563e-04,  7.58905053e-01,\n",
       "           4.72448260e-01,  9.66189981e-01,  1.62234616e+00]],\n",
       "\n",
       "        [[ 1.93997490e+00,  6.81192160e-01, -8.03075433e-02,\n",
       "           5.46523690e-01,  1.42587686e+00,  2.64375997e+00],\n",
       "         [ 9.12253916e-01,  3.94608229e-01,  0.00000000e+00,\n",
       "           4.11679834e-01,  1.47785544e+00,  2.36596799e+00],\n",
       "         [ 5.65907955e-01, -1.71363965e-01,  7.58905053e-01,\n",
       "          -3.51288259e-01,  6.02509797e-01,  1.19404054e+00]],\n",
       "\n",
       "        [[ 2.28166389e+00,  4.95497584e-01,  7.58905053e-01,\n",
       "           1.16787457e+00, -2.98210740e-01,  3.38283730e+00],\n",
       "         [ 1.03474855e+00,  4.99601722e-01,  7.58905053e-01,\n",
       "           7.71975160e-01, -3.60902339e-01,  2.81056571e+00],\n",
       "         [ 2.69413441e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.54669434e-01,  0.00000000e+00,  0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 1.45331573e+00,  2.86263317e-01,  0.00000000e+00,\n",
       "           1.07243955e+00,  1.66326213e+00,  4.15648508e+00],\n",
       "         [ 6.49315238e-01,  5.44063926e-01, -2.08554804e-01,\n",
       "           4.81083900e-01,  1.23342049e+00,  2.55023432e+00],\n",
       "         [-1.94144100e-02, -1.94191992e-01,  7.58905053e-01,\n",
       "           3.82718056e-01,  1.35325873e+00,  2.16109657e+00]],\n",
       "\n",
       "        [[ 1.19176221e+00,  7.44622111e-01, -2.08554804e-01,\n",
       "           7.17305481e-01,  1.57166851e+00,  3.28320456e+00],\n",
       "         [ 8.11948478e-01,  4.53602254e-01,  0.00000000e+00,\n",
       "           5.09399533e-01,  1.55815244e+00,  2.61612153e+00],\n",
       "         [-4.66441214e-02, -4.54260260e-02,  7.58905053e-01,\n",
       "          -6.18904829e-03,  1.35391784e+00,  1.74001622e+00]],\n",
       "\n",
       "        [[ 2.14352417e+00,  4.64383185e-01,  7.96725452e-01,\n",
       "           1.39076364e+00, -2.85700858e-01,  3.82291889e+00],\n",
       "         [ 1.62419248e+00,  4.47773576e-01,  9.41262066e-01,\n",
       "           8.21356893e-01, -3.60902339e-01,  2.79925489e+00],\n",
       "         [ 2.64704227e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.23145416e-01,  1.12968750e-01,  0.00000000e+00]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "embedded_inputs.edge_embed"
   ]
  },
  {
   "source": [
    "# Modules: Decoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[0, 2, 1],\n",
       "       [0, 1, 2]])>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model = AttentionDecoder(units, aggregation_graph='mean', n_heads=3)\n",
    "makespan, ll, pi = model(embedded_inputs)\n",
    "pi"
   ]
  },
  {
   "source": [
    "# All together"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 10), dtype=int64, numpy=\n",
       "array([[2, 8, 7, 3, 1, 4, 9, 0, 6, 5],\n",
       "       [1, 9, 2, 5, 6, 4, 7, 3, 8, 0],\n",
       "       [6, 4, 3, 9, 7, 8, 5, 2, 1, 0],\n",
       "       [2, 3, 7, 6, 8, 9, 1, 5, 4, 0],\n",
       "       [4, 8, 3, 2, 1, 7, 9, 6, 0, 5],\n",
       "       [5, 4, 9, 7, 8, 2, 3, 1, 6, 0],\n",
       "       [9, 5, 6, 7, 4, 8, 3, 2, 0, 1],\n",
       "       [9, 3, 8, 1, 2, 7, 5, 4, 6, 0],\n",
       "       [5, 9, 2, 7, 6, 8, 3, 0, 1, 4],\n",
       "       [5, 7, 4, 1, 3, 6, 2, 8, 9, 0],\n",
       "       [3, 7, 8, 9, 1, 6, 2, 4, 5, 0],\n",
       "       [8, 5, 2, 3, 9, 6, 7, 4, 1, 0],\n",
       "       [5, 3, 1, 2, 6, 9, 7, 8, 4, 0],\n",
       "       [2, 9, 1, 4, 7, 6, 5, 3, 8, 0],\n",
       "       [6, 7, 3, 5, 8, 9, 2, 1, 4, 0],\n",
       "       [6, 2, 7, 9, 5, 1, 3, 8, 4, 0],\n",
       "       [6, 3, 4, 1, 9, 2, 7, 8, 5, 0],\n",
       "       [7, 2, 9, 6, 1, 3, 4, 8, 5, 0],\n",
       "       [2, 6, 5, 9, 3, 7, 8, 1, 4, 0],\n",
       "       [6, 5, 2, 4, 7, 8, 9, 3, 1, 0],\n",
       "       [0, 3, 1, 7, 8, 9, 5, 6, 4, 2],\n",
       "       [7, 1, 9, 6, 4, 3, 2, 8, 5, 0],\n",
       "       [5, 8, 4, 3, 1, 7, 9, 2, 6, 0],\n",
       "       [1, 5, 6, 3, 9, 7, 2, 4, 8, 0],\n",
       "       [0, 8, 9, 1, 7, 2, 5, 4, 6, 3],\n",
       "       [4, 2, 9, 5, 3, 1, 7, 8, 6, 0],\n",
       "       [3, 4, 8, 9, 6, 7, 2, 5, 0, 1],\n",
       "       [8, 2, 4, 5, 9, 3, 1, 7, 0, 6],\n",
       "       [4, 8, 5, 6, 3, 9, 2, 7, 1, 0],\n",
       "       [5, 3, 8, 7, 2, 1, 9, 6, 4, 0],\n",
       "       [6, 1, 5, 4, 3, 9, 8, 0, 7, 2],\n",
       "       [4, 7, 9, 6, 2, 1, 8, 3, 0, 5],\n",
       "       [1, 7, 6, 3, 5, 2, 9, 8, 0, 4],\n",
       "       [4, 6, 5, 1, 9, 8, 7, 2, 0, 3],\n",
       "       [3, 8, 2, 7, 6, 1, 9, 0, 4, 5],\n",
       "       [0, 1, 6, 5, 7, 8, 9, 2, 3, 4],\n",
       "       [3, 6, 7, 9, 5, 2, 8, 1, 4, 0],\n",
       "       [5, 1, 4, 2, 3, 6, 8, 9, 7, 0],\n",
       "       [5, 3, 8, 4, 1, 7, 6, 9, 2, 0],\n",
       "       [2, 4, 8, 7, 6, 1, 9, 5, 0, 3],\n",
       "       [0, 5, 1, 9, 4, 2, 7, 3, 6, 8],\n",
       "       [7, 2, 6, 9, 4, 8, 1, 5, 0, 3],\n",
       "       [5, 6, 7, 1, 3, 4, 8, 9, 2, 0],\n",
       "       [8, 3, 4, 7, 6, 9, 5, 2, 1, 0],\n",
       "       [3, 5, 6, 4, 7, 9, 2, 8, 1, 0],\n",
       "       [5, 8, 2, 1, 4, 3, 6, 7, 9, 0],\n",
       "       [2, 4, 3, 6, 5, 1, 7, 8, 9, 0],\n",
       "       [3, 6, 4, 5, 1, 2, 7, 9, 8, 0],\n",
       "       [3, 8, 2, 5, 4, 9, 1, 7, 6, 0],\n",
       "       [8, 3, 1, 6, 2, 9, 5, 7, 0, 4],\n",
       "       [3, 7, 4, 1, 2, 5, 8, 9, 6, 0],\n",
       "       [4, 6, 9, 8, 2, 1, 5, 3, 7, 0],\n",
       "       [6, 7, 3, 9, 2, 5, 1, 4, 8, 0],\n",
       "       [2, 5, 1, 4, 6, 7, 9, 8, 3, 0],\n",
       "       [1, 4, 3, 6, 2, 7, 5, 8, 9, 0],\n",
       "       [4, 6, 5, 3, 9, 2, 1, 8, 7, 0],\n",
       "       [8, 9, 6, 7, 4, 2, 3, 0, 5, 1],\n",
       "       [9, 5, 1, 3, 7, 6, 8, 4, 2, 0],\n",
       "       [7, 5, 2, 6, 1, 3, 4, 9, 8, 0],\n",
       "       [4, 3, 5, 2, 1, 8, 9, 6, 7, 0],\n",
       "       [7, 6, 2, 1, 9, 8, 5, 4, 0, 3],\n",
       "       [5, 6, 4, 1, 2, 9, 3, 8, 7, 0],\n",
       "       [0, 2, 7, 1, 9, 3, 4, 5, 8, 6],\n",
       "       [3, 2, 8, 5, 6, 1, 7, 4, 9, 0]])>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "n_instances = 640\n",
    "instance_size = (2, 8)\n",
    "batch_size = 64\n",
    "units = 64  # embedding dims\n",
    "layers = 2\n",
    "\n",
    "dataset = make_sparse_data(n_instances, msp_size=instance_size, random_state=2021)\n",
    "batch_dataset = dataset.batch(batch_size)\n",
    "inputs = list(batch_dataset.take(1))[0]\n",
    "\n",
    "ecoder_model = GGCNEncoder(units, layers)\n",
    "embedded_inputs = ecoder_model(inputs)\n",
    "\n",
    "n_heads = 8\n",
    "model = AttentionDecoder(units, aggregation_graph='mean', n_heads=n_heads)\n",
    "makespan, ll, pi = model(embedded_inputs)\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=False>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "inputs.adj_matrix[0]\n",
    "\n",
    "\n",
    "tf.math.reduce_all(tf.math.equal(inputs.adj_matrix[1], inputs.adj_matrix[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 0 1 1 0 0 1 1 1]\n [1 0 1 1 1 1 1 1 1 1]\n [0 1 0 1 1 1 1 1 1 1]\n [1 1 1 0 1 1 1 1 1 1]\n [1 1 1 1 0 1 1 1 1 1]\n [0 1 1 1 1 0 1 1 1 1]\n [0 1 1 1 1 1 0 1 1 1]\n [1 1 1 1 1 1 1 0 1 1]\n [1 1 1 1 1 1 1 1 0 0]\n [1 1 1 1 1 1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "print(inputs.adj_matrix[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 1 1 1 1 1 1 1 1]\n [1 0 0 1 0 1 0 1 1 1]\n [1 0 0 1 1 1 1 1 1 1]\n [1 1 1 0 1 1 1 1 1 1]\n [1 0 1 1 0 1 1 1 1 1]\n [1 1 1 1 1 0 1 1 1 1]\n [1 0 1 1 1 1 0 1 1 1]\n [1 1 1 1 1 1 1 0 1 1]\n [1 1 1 1 1 1 1 1 0 0]\n [1 1 1 1 1 1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.adj_matrix[7].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "from tensorflow import Tensor\n",
    "\n",
    "class MSPState:\n",
    "\n",
    "    def __init__(self, inputs):\n",
    "        \"\"\" \"\"\"\n",
    "        self.adj_matrix = inputs.adj_matrix\n",
    "        self.node_embed = inputs.node_embed\n",
    "        \n",
    "        batch_size, num_nodes, node_embed_dims = self.node_embed.shape\n",
    "        \n",
    "        self._first_node = tf.zeros((batch_size,1), dtype=tf.int64)\n",
    "        self._last_node = self._first_node\n",
    "        self._visited = tf.zeros((batch_size,1,num_nodes), dtype=tf.int64)\n",
    "        self._makespan = tf.zeros((batch_size,1))\n",
    "\n",
    "        self.i = tf.zeros(1, dtype=tf.int64) # # Vector with length num_steps\n",
    "        self.ids = tf.range(5, delta=1, dtype=tf.int64)[:, None] #  # Add steps dimension\n",
    "        #self._step_num = tf.zeros(1, dtype=tf.int64)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def first_node(self):\n",
    "        return self._first_node\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        # self._node_embed = None\n",
    "        # self._edge_embed = None\n",
    "        # self._adj_matrix = None\n",
    "        # self._first_job = None\n",
    "        # self._last_job = None\n",
    "\n",
    "    # @property\n",
    "    # def node_embed(self):\n",
    "    #     return self._node_embed\n",
    "\n",
    "    # @node_embed.setter\n",
    "    # def node_embed(self, node_embed):\n",
    "    #     self._node_embed = node_embed\n",
    "\n",
    "    # @property\n",
    "    # def adj_matrix(self):\n",
    "    #     return self._adj_matrix\n",
    "\n",
    "    # @adj_matrix.setter\n",
    "    # def adj_matrix(self, adj_matrix):\n",
    "    #     self._adj_matrix = adj_matrix\n",
    "\n",
    "    # def initialize(self, inputs):\n",
    "    #     self.adj_matrix = inputs.adj_matrix\n",
    "    #    return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MSPSolution:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # sequence: Tensor\n",
    "    # makespan: Tensor\n",
    "    # a: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]), <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       " array([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])>)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import torch\n",
    "torch.arange(5, dtype=torch.int64)[:, None], tf.range(5, delta=1, dtype=tf.int64)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSPSparseGraph2(NamedTuple):\n",
    "    \"\"\" \"\"\"\n",
    "    adj_matrix: Tensor\n",
    "    node_features: Tensor\n",
    "    edge_features: Tensor\n",
    "    alpha: Tensor\n",
    "\n",
    "    @property\n",
    "    def num_node(self):\n",
    "        return self.adj_matrix.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "class A(NamedTuple):\n",
    "\n",
    "    a: int\n",
    "\n",
    "    @property\n",
    "    def num(self):\n",
    "        return self.a\n",
    "\n",
    "    # jane._replace(a=26)\n",
    "\n",
    "\n",
    "class C(\n",
    "    NamedTuple(\n",
    "        'SSSSS',\n",
    "        A._field_types.items()\n",
    "    ),\n",
    "    A\n",
    "):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "class B(\n",
    "    NamedTuple(\n",
    "        'SSSB',\n",
    "        [\n",
    "            *A._field_types.items(),\n",
    "            ('weight', int)\n",
    "        ]\n",
    "    ),\n",
    "    A\n",
    "):\n",
    "    @property\n",
    "    def h(self):\n",
    "        return self.weight\n",
    "\n",
    "\n",
    "# class B(namedtuple('SSSB', [*A._fields, \"weight\"]), A):\n",
    "#     #[*A._fields, \"weight\"]\n",
    "\n",
    "#     @property\n",
    "#     def h(self):\n",
    "#         return self.weight\n",
    "\n",
    "    \n",
    "\n",
    "    # def __getitem__(self, key):\n",
    "    #     return self[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "B(a=34, weight=34)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#B(A(a=90)._asdict(), weight=90)\n",
    "#B(**A(a=9090)._asdict(), weight=90).num\n",
    "#Ba = 2343, weight=23).num\n",
    "#dir(B)\n",
    "#C(a=90)\n",
    "B(*(34,), weight=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('a', int)]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "list(A._field_types.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('a', int)])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "A._field_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fun() got an unexpected keyword argument 'adj_matrix'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-11550ff00769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fun() got an unexpected keyword argument 'adj_matrix'"
     ]
    }
   ],
   "source": [
    "def fun(a):\n",
    "    print(a)\n",
    "\n",
    "fun(**inputs._asdict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['a', ('v', 'd')]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "[*A._field_types, ('v','d')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for attr, val in inputs._asdict().items():\n",
    "#     print(attr, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: __class__ not set defining 'AttentionModelFixed' as <class '__main__.AttentionModelFixed'>. Was __classcell__ propagated to type.__new__?\n  \n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "class AttentionModelFixed(NamedTuple):\n",
    "    \"\"\"\n",
    "    Context for AttentionModel decoder that is fixed during decoding so can be precomputed/cached\n",
    "    This class allows for efficient indexing of multiple Tensors at once\n",
    "    \"\"\"\n",
    "    node_embeddings: torch.Tensor\n",
    "    context_node_projected: torch.Tensor\n",
    "    glimpse_key: torch.Tensor\n",
    "    glimpse_val: torch.Tensor\n",
    "    logit_key: torch.Tensor\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if tf.is_tensor(key) or isinstance(key, slice):\n",
    "            return AttentionModelFixed(\n",
    "                node_embeddings=self.node_embeddings[key],\n",
    "                context_node_projected=self.context_node_projected[key],\n",
    "                glimpse_key=self.glimpse_key[:, key],  # dim 0 are the heads\n",
    "                glimpse_val=self.glimpse_val[:, key],  # dim 0 are the heads\n",
    "                logit_key=self.logit_key[key]\n",
    "            )\n",
    "        return super(AttentionModelFixed, self).__getitem__(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from msp.layers import GGCNLayer\n",
    "from msp.graphs import MSPSparseGraph\n",
    "from msp.solutions import MSPState\n",
    "\n",
    "class AttentionDecoder(Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 units,\n",
    "                 *args, \n",
    "                 activation='relu',\n",
    "                 aggregation_graph='mean',\n",
    "                 n_heads=2, # make it 8\n",
    "                 mask_inner=True,\n",
    "                 tanh_clipping=10,\n",
    "                 decode_type='sampling',\n",
    "                 extra_logging=False,\n",
    "                 **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        super(AttentionDecoder, self).__init__(*args, **kwargs)\n",
    "        self.aggregation_graph = aggregation_graph\n",
    "        self.n_heads = n_heads\n",
    "        self.mask_inner = mask_inner\n",
    "        self.tanh_clipping = tanh_clipping\n",
    "        self.decode_type = decode_type\n",
    "        self.extra_logging = extra_logging\n",
    "\n",
    "        embedding_dim = units\n",
    "        \n",
    "        self.W_placeholder = self.add_weight(shape=(2*embedding_dim,),\n",
    "                                initializer='random_uniform', #Placeholder should be in range of activations (think)\n",
    "                                name='W_placeholder',\n",
    "                                trainable=True)\n",
    "\n",
    "        graph_embed_shape = tf.TensorShape((None, units))\n",
    "        self.fixed_context_layer = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.fixed_context_layer.build(graph_embed_shape)\n",
    "\n",
    "        # For each node we compute (glimpse key, glimpse value, logit key) so 3 * embedding_dim\n",
    "        project_node_embeddings_shape = tf.TensorShape((None, None, None, units))\n",
    "        self.project_node_embeddings = tf.keras.layers.Dense(3*units, use_bias=False)\n",
    "        self.project_node_embeddings.build(project_node_embeddings_shape)\n",
    "\n",
    "        #\n",
    "        # Embedding of first and last node\n",
    "        step_context_dim = 2*units\n",
    "        project_step_context_shape = tf.TensorShape((None, None, step_context_dim))\n",
    "        self.project_step_context = tf.keras.layers.Dense(embedding_dim, use_bias=False)\n",
    "        self.project_step_context.build(project_step_context_shape)\n",
    "\n",
    "        assert embedding_dim % n_heads == 0\n",
    "        # Note n_heads * val_dim == embedding_dim so input to project_out is embedding_dim\n",
    "\n",
    "        project_out_shape = tf.TensorShape((None, None, 1, embedding_dim))\n",
    "        self.project_out = tf.keras.layers.Dense(embedding_dim, use_bias=False)\n",
    "        self.project_out.build(project_out_shape)\n",
    "\n",
    "\n",
    "        # self.context_layer = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        # self.mha_layer = None\n",
    "        \n",
    "\n",
    "        # dynamic router\n",
    "\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=False, return_pi=False):\n",
    "        \"\"\" \"\"\"\n",
    "        state = MSPState(inputs)\n",
    "\n",
    "        node_embedding = inputs.node_embed\n",
    "\n",
    "        # AttentionModelFixed(node_embedding, fixed_context, *fixed_attention_node_data)\n",
    "        fixed = self._precompute(node_embedding)\n",
    "\n",
    "\n",
    "        # for i in range(num_steps):\n",
    "            # i == 0 should be machine \n",
    "            # AttentionCell(inputs, states)\n",
    "\n",
    "        outputs = []\n",
    "        sequences = []\n",
    "\n",
    "        # i = 0\n",
    "        while not state.all_finished():\n",
    "            # B x 1 x V\n",
    "            # Get log probabilities of next action\n",
    "            log_p, mask = self._get_log_p(fixed, state)\n",
    "            \n",
    "            selected = self._select_node(\n",
    "                    tf.squeeze(tf.exp(log_p), axis=-2), tf.squeeze(mask, axis=-2)) # Squeeze out steps dimension\n",
    "\n",
    "            state.update(selected)\n",
    "\n",
    "            outputs.append(log_p[:, 0, :])\n",
    "            sequences.append(selected)\n",
    "            \n",
    "            # if i == 1:\n",
    "            #     break\n",
    "            # i+=1\n",
    "        \n",
    "        _log_p, pi = tf.stack(outputs, axis=1), tf.stack(sequences, axis=1)\n",
    "\n",
    "        if self.extra_logging:\n",
    "            self.log_p_batch = _log_p\n",
    "            self.log_p_sel_batch = tf.gather(tf.squeeze(_log_p,axis=-2), pi, batch_dims=1)\n",
    "\n",
    "        # # Get predicted costs\n",
    "        # cost, mask = self.problem.get_costs(nodes, pi)\n",
    "        mask = None\n",
    "\n",
    "        ###################################################\n",
    "        # Need Clarity #############################################################\n",
    "        # loglikelihood \n",
    "        ll = self._calc_log_likelihood(_log_p, pi, mask)\n",
    "\n",
    "        ## Just for checking\n",
    "        return_pi = True    \n",
    "        if return_pi:\n",
    "            return state.makespan, ll, pi\n",
    "\n",
    "        return state.makespan, ll\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def _precompute(self, node_embedding, num_steps=1):\n",
    "\n",
    "        graph_embed = self._get_graph_embed(node_embedding)\n",
    "\n",
    "        fixed_context = self.fixed_context_layer(graph_embed)\n",
    "        # fixed context = (batch_size, 1, embed_dim) to make broadcastable with parallel timesteps\n",
    "        fixed_context = tf.expand_dims(fixed_context, axis=-2)\n",
    "\n",
    "        glimpse_key_fixed, glimpse_val_fixed, logit_key_fixed  = tf.split(\n",
    "            self.project_node_embeddings(tf.expand_dims(node_embedding, axis=-3)),\n",
    "            num_or_size_splits=3,\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        # No need to rearrange key for logit as there is a single head\n",
    "        fixed_attention_node_data = (\n",
    "            self._make_heads(glimpse_key_fixed, num_steps),\n",
    "            self._make_heads(glimpse_val_fixed, num_steps),\n",
    "            logit_key_fixed\n",
    "        )\n",
    "        return AttentionModelFixed(node_embedding, fixed_context, *fixed_attention_node_data)\n",
    "\n",
    "    def _get_graph_embed(self, node_embedding):\n",
    "        \"\"\" \"\"\"\n",
    "        if self.aggregation_graph == \"sum\":\n",
    "            graph_embed = tf.reduce_sum(node_embedding, axis=-2)\n",
    "        elif self.aggregation_graph == \"max\":\n",
    "            graph_embed = tf.reduce_max(node_embedding, axis=-2)\n",
    "        elif self.aggregation_graph == \"mean\":\n",
    "            graph_embed = tf.reduce_mean(node_embedding, axis=-2)\n",
    "        else:  # Default: dissable graph embedding\n",
    "            graph_embed = tf.reduce_sum(node_embedding, axis=-2) * 0.0\n",
    "\n",
    "        return graph_embed\n",
    "\n",
    "    def _make_heads(self, v, num_steps=None):\n",
    "\n",
    "        assert num_steps is None or v.shape[1] == 1 or v.shape[1] == num_steps\n",
    "        batch_size, _, num_nodes, embed_dims = v.shape\n",
    "        num_steps = num_steps if num_steps else 1\n",
    "        head_dims = embed_dims//self.n_heads\n",
    "\n",
    "        # M x B x N x V x (H/M)\n",
    "        return tf.transpose(\n",
    "            tf.broadcast_to(\n",
    "                tf.reshape(v, shape=[batch_size, v.shape[1], num_nodes, self.n_heads, head_dims]),\n",
    "                shape=[batch_size, num_steps, num_nodes, self.n_heads, head_dims]\n",
    "            ),\n",
    "            perm=[3, 0, 1, 2, 4]\n",
    "        )\n",
    "\n",
    "    def _get_log_p(self, fixed, state, normalize=True):\n",
    "        # Compute query = context node embedding\n",
    "        \n",
    "        # B x 1 x H\n",
    "        query = fixed.context_node_projected + \\\n",
    "                self.project_step_context(self._get_parallel_step_context(fixed.node_embeddings, state))\n",
    "        \n",
    "        # Compute keys and values for the nodes\n",
    "        glimpse_K, glimpse_V, logit_K = self._get_attention_node_data(fixed, state)\n",
    "\n",
    "        # Compute the mask, for masking next action based on previous actions\n",
    "        mask = state.get_mask()\n",
    "        graph_mask = state.get_graph_mask()\n",
    "\n",
    "        # Compute logits (unnormalized log_p)\n",
    "        log_p, glimpse = self._one_to_many_logits(query, glimpse_K, glimpse_V, logit_K, mask, graph_mask)\n",
    "\n",
    "        # [B x N x V]\n",
    "        # log-softmax activation function so that we get log probabilities over actions\n",
    "        if normalize:\n",
    "            log_p = tf.nn.log_softmax(log_p/1.0, axis=-1)\n",
    "\n",
    "        assert not tf.reduce_any(tf.math.is_nan(log_p)), \"Log probabilities over the nodes should be defined\"\n",
    "\n",
    "        return log_p, mask\n",
    "\n",
    "\n",
    "    def _get_parallel_step_context(self, node_embedding, state, from_depot=False):\n",
    "        \"\"\"\n",
    "        Returns the context per step, optionally for multiple steps at once \n",
    "        (for efficient evaluation of the model)\n",
    "        \"\"\"\n",
    "        # last_node at time t\n",
    "        last_node = state.get_current_node()\n",
    "        batch_size, num_steps = last_node.shape\n",
    "\n",
    "        if num_steps == 1:  # We need to special case if we have only 1 step, may be the first or not\n",
    "            if state.i.numpy()[0] == 0:\n",
    "                # First and only step, ignore prev_a (this is a placeholder)\n",
    "                # B x 1 x 2H\n",
    "                return tf.broadcast_to(self.W_placeholder[None, None, :], \n",
    "                                       shape=[batch_size, 1, self.W_placeholder.shape[-1]])\n",
    "            else:\n",
    "                return tf.concat(\n",
    "                    [\n",
    "                        tf.gather(node_embedding,state.first_node,batch_dims=1), \n",
    "                        tf.gather(node_embedding,last_node,batch_dims=1)  \n",
    "                    ],\n",
    "                    axis=-1\n",
    "                )\n",
    "                \n",
    "                # print('$'*20)\n",
    "                # node_embedding = torch.from_numpy(node_embedding.numpy())\n",
    "                # f = torch.from_numpy(state.first_node.numpy())\n",
    "                # l = torch.from_numpy(state.last_node.numpy())\n",
    "                # GG = node_embedding\\\n",
    "                # .gather(\n",
    "                #     1,\n",
    "                #     torch.cat((f, l), 1)[:, :, None].expand(batch_size, 2, node_embedding.size(-1))\n",
    "                # ).view(batch_size, 1, -1)\n",
    "                # print(GG)\n",
    "                # print('$'*20)\n",
    "                # ##############################################\n",
    "                # # PENDING\n",
    "                # ##############################################\n",
    "                # pass\n",
    "\n",
    "    def _get_attention_node_data(self, fixed, state):\n",
    "        return fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key\n",
    "\n",
    "    def _one_to_many_logits(self, query, glimpse_K, glimpse_V, logit_K, mask, graph_mask=None):\n",
    "        batch_size, num_steps, embed_dim = query.shape\n",
    "        query_size = key_size = val_size = embed_dim // self.n_heads\n",
    "\n",
    "        # M x B x N x 1 x (H/M)\n",
    "        # Compute the glimpse, rearrange dimensions to (n_heads, batch_size, num_steps, 1, key_size)\n",
    "        glimpse_Q = tf.transpose(\n",
    "            tf.reshape(\n",
    "                query, # B x 1 x H\n",
    "                shape=[batch_size, num_steps, self.n_heads, 1, query_size]\n",
    "            ),\n",
    "            perm=[2, 0, 1, 3, 4]\n",
    "        )\n",
    "\n",
    "        # [M x B x N x 1 x (H/M)] X [M x B x N x (H/M) x V] = [M x B x N x 1 x V]\n",
    "        # Batch matrix multiplication to compute compatibilities (n_heads, batch_size, num_steps, graph_size)\n",
    "        compatibility = tf.matmul(glimpse_Q, tf.transpose(glimpse_K, [0,1,2,4,3])) / math.sqrt(query_size)\n",
    "        \n",
    "        mask_temp = tf.cast(tf.broadcast_to(mask[None, :, :, None, :], shape=compatibility.shape), dtype=tf.double)\n",
    "        compatibility = tf.cast(compatibility, dtype=tf.double) + (mask_temp * -1e9)\n",
    "\n",
    "        graph_mask_temp = tf.cast(tf.broadcast_to(graph_mask[None, :, :, None, :], shape=compatibility.shape), dtype=tf.double)\n",
    "        compatibility = tf.cast(compatibility, dtype=tf.double) + (graph_mask_temp * -1e9)\n",
    "\n",
    "        compatibility = tf.cast(compatibility, dtype=tf.float32)        \n",
    "\n",
    "        # compatibility[tf.broadcast_to(mask[None, :, :, None, :], shape=compatibility.shape)] = -1e10\n",
    "        # compatibility[tf.broadcast_to(graph_mask[None, :, :, None, :], shape=compatibility.shape)] = -1e10\n",
    "\n",
    "        # attention weights a(c,j): \n",
    "        attention_weights = tf.nn.softmax(compatibility, axis=-1)\n",
    "\n",
    "\n",
    "        # [M x B x N x 1 x V] x [M x B x N x V x (H/M)] = [M x B x N x 1 x (H/M)]\n",
    "        heads = tf.matmul(attention_weights, glimpse_V)\n",
    "       \n",
    "        # B x N x 1 x H\n",
    "        # Project to get glimpse/updated context node embedding (batch_size, num_steps, embedding_dim)\n",
    "        glimpse = self.project_out(\n",
    "            tf.reshape(\n",
    "                tf.transpose(heads, perm=[1, 2, 3, 0, 4]),\n",
    "                shape=[batch_size, num_steps, 1, self.n_heads*val_size]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # B x N x 1 x H\n",
    "        # Now projecting the glimpse is not needed since this can be absorbed into project_out\n",
    "        # final_Q = self.project_glimpse(glimpse)\n",
    "        final_Q = glimpse\n",
    "\n",
    "\n",
    "        # [B x N x 1 x H] x [B x 1 x H x V] = [B x N x 1 x V] --> [B x N x V] (Squeeze) \n",
    "        # Batch matrix multiplication to compute logits (batch_size, num_steps, graph_size)\n",
    "        # logits = 'compatibility'\n",
    "        logits = tf.squeeze(tf.matmul(final_Q, tf.transpose(logit_K, perm=[0,1,3,2])),\n",
    "                            axis=-2) / math.sqrt(final_Q.shape[-1])\n",
    "\n",
    "        logits = logits + ( tf.cast(graph_mask, dtype=tf.float32) * -1e9)\n",
    "        logits = tf.math.tanh(logits) * self.tanh_clipping\n",
    "        logits = logits + ( tf.cast(mask, dtype=tf.float32) * -1e9)\n",
    "\n",
    "        # logits[graph_mask] = -1e10 \n",
    "        # logits = torch.tanh(logits) * self.tanh_clipping\n",
    "        # logits[mask] = -1e10\n",
    "        \n",
    "        return logits, tf.squeeze(glimpse, axis=-2)\n",
    "\n",
    "    \n",
    "    def _select_node(self, probs, mask):\n",
    "        assert tf.reduce_all(probs == probs) == True, \"Probs should not contain any nans\"\n",
    "\n",
    "        if self.decode_type == \"greedy\":\n",
    "            selected = tf.math.argmax(probs, axis=1)\n",
    "            assert not tf.reduce_any(tf.cast(tf.gather_nd(mask, tf.expand_dims(selected, axis=-1), batch_dims=1), dtype=tf.bool)), \"Decode greedy: infeasible action has maximum probability\"\n",
    "\n",
    "        elif self.decode_type == \"sampling\":\n",
    "            dist = tfp.distributions.Multinomial(total_count=1, probs=probs)\n",
    "            selected = tf.argmax(dist.sample(), axis=1)\n",
    "\n",
    "            # Check if sampling went OK\n",
    "            while tf.reduce_any(tf.cast(tf.gather_nd(mask, tf.expand_dims(selected, axis=-1), batch_dims=1), dtype=tf.bool)):\n",
    "                print('Sampled bad values, resampling!')\n",
    "                selected = tf.argmax(dist.sample(), axis=1)\n",
    "\n",
    "        else:\n",
    "            assert False, \"Unknown decode type\"\n",
    "        return selected\n",
    "\n",
    "    \n",
    "    def _calc_log_likelihood(self, _log_p, a, mask):\n",
    "        \n",
    "        # Get log_p corresponding to selected actions\n",
    "        batch_size, steps_count = a.shape\n",
    "        indices = tf.concat([\n",
    "        tf.expand_dims(tf.broadcast_to(tf.range(steps_count, dtype=tf.int64), shape=a.shape), axis=-1),\n",
    "        tf.expand_dims(a, axis=-1)],\n",
    "        axis=-1\n",
    "        )\n",
    "        log_p = tf.gather_nd(_log_p, indices, batch_dims=1)\n",
    "        \n",
    "\n",
    "        # _log_p = torch.from_numpy(_log_p.numpy())\n",
    "        # a = torch.from_numpy(a.numpy())\n",
    "        # AA = _log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n",
    "        # print(AA)\n",
    "        # print(log_p)\n",
    "        # print('DONE')\n",
    "        \n",
    "\n",
    "        # Get log_p corresponding to selected actions\n",
    "        # log_p = tf.gather(tf.squeeze(_log_p,axis=-2), a, batch_dims=1) #_log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # Optional: mask out actions irrelevant to objective so they do not get reinforced\n",
    "        if mask is not None:\n",
    "            log_p[mask] = 0\n",
    "\n",
    "        # Why??????\n",
    "        # assert (log_p > -1000).data.all(), \"Logprobs should not be -inf, check sampling procedure!\"\n",
    "\n",
    "        # Calculate log_likelihood\n",
    "        return tf.reduce_sum(log_p, axis=1) # log_p.sum(1)\n",
    "\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x = tf.constant([[True,  True], [False, False]])\n",
    "# # assert not tf.reduce_any(x), \"asdf\"\n",
    "# tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "#     from_logits=True, reduction='none')([]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.tensor([[[2,3],[5,2]], [[6,1],[0,4]]])\n",
    "# indices = torch.tensor([[[0, 0]],[[0, 0]]])\n",
    "# torch.gather(t, 1, indices)\n",
    " \n",
    "# # t = tf.constant([[[2,3],[5,2]], [[6,1],[0,4]]])\n",
    "# # indices = tf.constant([[0,0,0]])\n",
    "# # tf.gather_nd(t, indices=indices).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #tf.gather_nd()\n",
    "# # t = tf.constant([[[1,0],[1,0]], [[0,1],[1,1]]])\n",
    "# # t = embedded_inputs.adj_matrix\n",
    "# # indices = tf.constant([[0], [0]])\n",
    "# # indices = tf.expand_dims(indices, axis=-1)\n",
    "\n",
    "# # ~tf.cast(tf.gather_nd(t, indices=indices, batch_dims=1), tf.bool)\n",
    "# a = tf.constant([-3.0,-1.0, 0.0,1.0,3.0], dtype = tf.float32)\n",
    "# b = tf.keras.activations.tanh(a) \n",
    "# c = tf.math.tanh(a)\n",
    "# b.numpy(), c.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "array([[2, 1, 0],\n",
       "       [2, 1, 0]])>"
      ]
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "source": [
    "model = AttentionDecoder(6, aggregation_graph='mean', n_heads=3)\n",
    "makespan, ll, pi = model(embedded_inputs)\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 2, 3])>"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "tf.range(4, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
       "array([[[0, 0],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 1]]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "\n",
    "indices = [[[1, 0]], [[0, 1]]]\n",
    "params = [[['a0', 'b0'], ['c0', 'd0']],\n",
    "            [['a1', 'b1'], ['c1', 'd1']]]\n",
    "#output = [['c0'], ['b1']]\n",
    "tf.gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-197-8979dfe3162c>, line 2)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-197-8979dfe3162c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    [[[0 1]\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = tf.Tensor(\n",
    "[[[0,1]\n",
    "  [1,2]],\n",
    "\n",
    " [[0,0]\n",
    "#   [1 1]]], shape=(2, 2, 2), dtype=int64)\n",
    "# tf.Tensor(\n",
    "# [[[-1.0886807e+00 -1.2036482e+00 -1.0126851e+00]\n",
    "#   [-9.8199100e+00 -1.0000000e+09 -5.4357959e-05]]\n",
    "\n",
    "#  [[-5.4339290e-01 -1.6555539e+00 -1.4773605e+00]\n",
    "#   [-1.0000000e+09 -7.7492166e-01 -6.1755723e-01]]], shape=(2, 2, 3), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.gather(\n",
    "                        1,\n",
    "                        torch.cat((state.first_a, current_node), 1)[:, :, None].expand(batch_size, 2, embeddings.size(-1))\n",
    "                    ).view(batch_size, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 1, 3), dtype=float32, numpy=\n",
       " array([[[0.53031623, 0.3536483 , 0.11603544]],\n",
       " \n",
       "        [[0.6530212 , 0.23223129, 0.11474745]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
       " array([[1],\n",
       "        [0]])>)"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "source": [
    "_log_p, pi#tf.expand_dims(pi,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.3536483],\n",
       "       [0.6530212]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "_log_p\n",
    "\n",
    "tf.gather(tf.squeeze(_log_p,axis=-2), pi, batch_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "_log_p = torch.Tensor(_log_p.numpy())\n",
    "pi = torch.from_numpy(tf.cast(pi, dtype=tf.int64).numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.3536],\n",
       "        [0.6530]])"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "log_p = _log_p.gather(2, pi.unsqueeze(-1)).squeeze(-1)\n",
    "log_p.sum(1) \n",
    "log_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.2306, 0.2705, 0.4989]],\n",
       "\n",
       "        [[0.2119, 0.2444, 0.5437]]])"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "# pi.unsqueeze(-1)\n",
    "# tf.cast(pi, dtype=tf.int64)\n",
    "_log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [0]])"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "# seq = [torch.Tensor(i.numpy()) for i in seq]\n",
    "# torch.stack(seq, 1)\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.5743043 , 0.37116084, 0.        ],\n",
       "       [0.70901567, 0.8906554 , 0.        ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "last_node = tf.constant([[0], [1]], dtype=tf.int64)\n",
    "\n",
    "cur_node = selected[:, tf.newaxis]\n",
    "cur_node #cur_node\n",
    "\n",
    "tf.gather_nd(\n",
    "tf.gather_nd(embedded_inputs.edge_features, tf.concat([last_node, cur_node], axis=1), batch_dims=1),\n",
    "tf.reshape(tf.range(2), shape=(2,1)), # feature_indexfor processing time\n",
    "batch_dims=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.5743043 ],\n",
       "       [0.70901567]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "A = tf.gather_nd(embedded_inputs.edge_features, tf.concat([last_node, cur_node], axis=1), batch_dims=1)[:,0:1]\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
       "array([[0],\n",
       "       [1]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "tf.reshape(tf.range(2), shape=(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[0.60597825, 0.73336935, 0.13894716, 0.3126731 , 1.        ],\n",
       "        [0.12816237, 0.1789931 , 0.75292546, 0.6621605 , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.82309866, 0.732225  , 0.06905627, 0.6721289 , 1.        ],\n",
       "        [0.8280144 , 0.2044694 , 0.617489  , 0.617701  , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "embedded_inputs.node_features[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.70246667],\n",
       "       [1.5321143 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "cur_node[:,tf.newaxis,:] #embedded_inputs.node_features[:, ]\n",
    "tf.gather_nd(embedded_inputs.edge_features, tf.concat([last_node, cur_node], axis=1), batch_dims=1)[:,0:1] + \\\n",
    "tf.gather_nd(embedded_inputs.node_features, cur_node, batch_dims=1)[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "cur_node\n",
    "\n",
    "tf.rank(tf.ones(30,10))\n",
    "\n",
    "t = tf.constant([[[1, 1, 1, 4], [2, 2, 2, 4]], [[3, 3, 3, 4], [4, 4, 4, 4]]])\n",
    "tf.rank(t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 3), dtype=uint8, numpy=\n",
       "array([[[0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0]]], dtype=uint8)>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "_visited = tf.zeros((batch_size,1,3), dtype=tf.uint8)\n",
    "_visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
       "array([[1],\n",
       "       [0]])>"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "cur_node #[:,:,None] #, tf.ones([2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[0, 1],\n",
       "       [1, 0]])>"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "tf.concat([tf.reshape(tf.range(2, dtype=tf.int64),cur_node.shape), cur_node], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tf.uint8"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "_visited.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 3), dtype=uint8, numpy=\n",
       "array([[[0, 1, 0]],\n",
       "\n",
       "       [[1, 0, 0]]], dtype=uint8)>"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "batch_size, _, _ = _visited.shape\n",
    "tf.tensor_scatter_nd_update( \n",
    "    tf.squeeze(_visited, axis=-2),\n",
    "    tf.concat([tf.reshape(tf.range(batch_size, dtype=tf.int64),cur_node.shape), cur_node], axis=1),\n",
    "    tf.ones((batch_size,), dtype=_visited.dtype)\n",
    ")[:,tf.newaxis,:]\n",
    "    \n",
    "    \n",
    "    #_visited, cur_node[:,:,None], tf.ones([2,1,1], dtype=tf.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "cur_node = selected[:, tf.newaxis]\n",
    "cur_node #cur_node\n",
    "\n",
    "tf.concat([cur_node, cur_node], axis=1)\n",
    "\n",
    "tf.gather_nd(\n",
    "tf.gather_nd(embedded_inputs.edge_features, tf.concat([cur_node, cur_node], axis=1), batch_dims=1),\n",
    "tf.zeros((2,1), dtype=tf.int32)\n",
    ")\n",
    "\n",
    "tf.gather_nd(embedded_inputs.edge_features, tf.concat([cur_node, cur_node], axis=1), batch_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "tf.zeros((2,), dtype=tf.int32)\n",
    "tf.range(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0.        , 0.        , 0.        ],\n",
       "         [0.5743043 , 0.37116084, 0.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.5743043 , 0.37116084, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.70901567, 0.8906554 , 0.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.70901567, 0.8906554 , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ]]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "embedded_inputs.edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'log_p' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-29c5565f8419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_p' is not defined"
     ]
    }
   ],
   "source": [
    "probs_ = tf.squeeze(tf.exp(log_p), axis=-2)\n",
    "tf.squeeze(mask, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[0.60597825, 0.73336935, 0.13894716, 0.3126731 , 1.        ],\n",
       "        [0.12816237, 0.1789931 , 0.75292546, 0.6621605 , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.82309866, 0.732225  , 0.06905627, 0.6721289 , 1.        ],\n",
       "        [0.8280144 , 0.2044694 , 0.617489  , 0.617701  , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "embedded_inputs.node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'log_p' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-572ef634e096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmask_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.squeeze(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_p' is not defined"
     ]
    }
   ],
   "source": [
    "probs = torch.Tensor(log_p.numpy()).exp()[:, 0, :]\n",
    "mask_ = torch.Tensor(mask.numpy())[:, 0, :]\n",
    "\n",
    "probs, probs.multinomial(1) #.squeeze(1)\n",
    "\n",
    "\n",
    "# _, selected = probs.max(1)\n",
    "# assert not mask_.gather(1, selected.unsqueeze(\n",
    "#                 -1)).data.any(), \"Decode greedy: infeasible action has maximum probability\"\n",
    "# mask_.gather(1, selected.unsqueeze(-1)) #.data.any()\n",
    "probs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [0]])"
      ]
     },
     "metadata": {},
     "execution_count": 275
    }
   ],
   "source": [
    "probs.multinomial(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 0])>"
      ]
     },
     "metadata": {},
     "execution_count": 294
    }
   ],
   "source": [
    "# p = [.2, .3, .5]\n",
    "# dist = tfp.distributions.Multinomial(total_count=1, probs=probs_)\n",
    "\n",
    "p = [[.1, .2, .7], [.3, .3, .4]]  # Shape [2, 3]\n",
    "\n",
    "dist = tfp.distributions.Multinomial(total_count=1, probs=probs_)\n",
    "selected = tf.argmax(dist.sample(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 215
    }
   ],
   "source": [
    "selected = tf.math.argmax(tf.squeeze(tf.exp(log_p), axis=-2), axis=1)\n",
    "\n",
    "assert not tf.reduce_any(tf.cast(tf.gather_nd(mask_, tf.expand_dims(selected, axis=-1), batch_dims=1), dtype=tf.bool)), \"Decode greedy: infeasible action has maximum probability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
       " array([[1],\n",
       "        [0]])>, tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]), <tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "source": [
    "tf.expand_dims(selected, axis=-1), mask_, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-305-6a8b95c4c4a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprobs_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprobs_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "probs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'compatibility' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-0f56842328b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'compatibility' is not defined"
     ]
    }
   ],
   "source": [
    "tf.broadcast_to(mask[None, :, None, :, :], shape=compatibility.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compatibility\n",
    "\n",
    "compatibility[graph_mask[None, :, :, None, :].expand_as(compatibility)] = -1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-7.8044e+00,  4.5678e-41, -7.8044e+00,  4.5678e-41, -4.2528e-01,\n",
       "           1.6527e-01, -1.7343e-01, -3.0582e-01, -5.5208e-02, -2.9920e-01,\n",
       "          -1.3644e-01,  4.3799e-01]],\n",
       "\n",
       "        [[-7.8044e+00,  4.5678e-41, -7.8044e+00,  4.5678e-41, -4.2528e-01,\n",
       "           1.6527e-01, -1.7343e-01, -3.0582e-01, -5.5208e-02, -2.9920e-01,\n",
       "          -1.3644e-01,  4.3799e-01]]], grad_fn=<ExpandBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "def _make_heads(v, num_steps=None):\n",
    "    assert num_steps is None or v.size(1) == 1 or v.size(1) == num_steps\n",
    "    n_heads = 2\n",
    "    return (\n",
    "        v.contiguous().view(v.size(0), v.size(1), v.size(2), n_heads, -1)\n",
    "        .expand(v.size(0), v.size(1) if num_steps is None else num_steps, v.size(2), n_heads, -1)\n",
    "        .permute(3, 0, 1, 2, 4)  # (n_heads, batch_size, num_steps, graph_size, head_dim)\n",
    "    )\n",
    "\n",
    "from torch import nn\n",
    "W_placeholder = nn.Parameter(torch.Tensor(2 * 6))\n",
    "W_placeholder[None, None, :].expand(2, 1, W_placeholder.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "tf.ones((3,4)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name '_make_heads2' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-269b1912abc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_make_heads2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_make_heads2' is not defined"
     ]
    }
   ],
   "source": [
    "_make_heads2(A, num_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name '_make_heads2' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9397c71accbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_make_heads2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_make_heads2' is not defined"
     ]
    }
   ],
   "source": [
    "_make_heads2(A, num_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "type object 'A' has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-8e9318239217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'A' has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "A.shape\n",
    "tf.broadcast_to(A, tf.TensorShape([-1, 4, None, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5, 3), dtype=float32, numpy=\n",
       " array([[[3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5, 3), dtype=float32, numpy=\n",
       " array([[[3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5, 3), dtype=float32, numpy=\n",
       " array([[[3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.]]], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "tf.split(\n",
    "tf.matmul(tf.ones((5,3))[None,:,:], tf.ones((3,3*3))),\n",
    "3,\n",
    "axis=-1\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 9), dtype=float32, numpy=\n",
       "array([[[3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3., 3., 3., 3., 3., 3.]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "tf.matmul(tf.ones((5,3))[None,:,:], tf.ones((3,3*3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 1.1431e+27,  1.7241e+25,  9.1084e-44,  0.0000e+00, -6.2840e-10,\n",
       "         3.0753e-41, -2.3967e-33,  4.5706e-41,  7.2697e+31,  1.8730e+31],\n",
       "       requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b224ef82fd7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "embeddings = torch.Tensor(embedded_inputs.node_features.numpy())\n",
    "\n",
    "torch.cat((state.first_a, current_node), 1)[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[0.60597825, 0.73336935, 0.13894716, 0.3126731 , 1.        ],\n",
       "        [0.12816237, 0.1789931 , 0.75292546, 0.6621605 , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.82309866, 0.732225  , 0.06905627, 0.6721289 , 1.        ],\n",
       "        [0.8280144 , 0.2044694 , 0.617489  , 0.617701  , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "embedded_inputs.node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "W_placeholder = nn.Parameter(torch.Tensor(2 * 5))\n",
    "\n",
    "\n",
    "W_placeholder[None, None, :].expand(batch_size, 1, W_placeholder.size(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "tf.constant(W_placeholder[None, None, :].detach().numpy()).shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "broadcast_to() got an unexpected keyword argument 'dim'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-c72bed19e307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tf.broadcast_to(\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_placeholder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m dim=0)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: broadcast_to() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Broadcast an array for a compatible shape.\n",
      "\n",
      "Broadcasting is the process of making arrays to have compatible shapes\n",
      "for arithmetic operations. Two shapes are compatible if for each\n",
      "dimension pair they are either equal or one of them is one. When trying\n",
      "to broadcast a Tensor to a shape, it starts with the trailing dimensions,\n",
      "and works its way forward.\n",
      "\n",
      "For example,\n",
      "\n",
      ">>> x = tf.constant([1, 2, 3])\n",
      ">>> y = tf.broadcast_to(x, [3, 3])\n",
      ">>> print(y)\n",
      "tf.Tensor(\n",
      "    [[1 2 3]\n",
      "     [1 2 3]\n",
      "     [1 2 3]], shape=(3, 3), dtype=int32)\n",
      "\n",
      "In the above example, the input Tensor with the shape of `[1, 3]`\n",
      "is broadcasted to output Tensor with shape of `[3, 3]`.\n",
      "\n",
      "When doing broadcasted operations such as multiplying a tensor\n",
      "by a scalar, broadcasting (usually) confers some time or space\n",
      "benefit, as the broadcasted tensor is never materialized.\n",
      "\n",
      "However, `broadcast_to` does not carry with it any such benefits.\n",
      "The newly-created tensor takes the full memory of the broadcasted\n",
      "shape. (In a graph context, `broadcast_to` might be fused to\n",
      "subsequent operation and then be optimized away, however.)\n",
      "\n",
      "Args:\n",
      "  input: A `Tensor`. A Tensor to broadcast.\n",
      "  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "    An 1-D `int` Tensor. The shape of the desired output.\n",
      "  name: A name for the operation (optional).\n",
      "\n",
      "Returns:\n",
      "  A `Tensor`. Has the same type as `input`.\n",
      "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "tf.broadcast_to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "W_placeholder[None, None, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[ 1.2512864 , -0.11654303,  0.427403  ,  0.6303492 ,  1.0807096 ,\n",
       "         0.7363432 ],\n",
       "       [ 1.875542  , -0.47257408,  1.0240463 ,  0.74093527,  2.416504  ,\n",
       "         1.2604753 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "tf.reduce_mean(embedded_inputs.node_features, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.6213, 0.0821, 0.7174, 1.1543, 2.0377, 1.2888],\n",
       "        [2.3475, 0.0000, 1.2708, 1.3155, 3.2248, 2.1935]])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "torch.Tensor(embedded_inputs.node_features.numpy()).max(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[ 1.6213439 , -0.49750236,  0.71744895,  0.73677236,\n",
       "          2.0377152 ,  1.2887579 ],\n",
       "        [ 1.1330049 ,  0.08210948,  0.13447253,  1.1542754 ,\n",
       "          0.79937   ,  0.9202718 ],\n",
       "        [ 0.9995105 ,  0.06576377,  0.43028754,  0.        ,\n",
       "          0.40504336,  0.        ]],\n",
       "\n",
       "       [[ 1.9401135 , -0.62696314,  1.2366322 ,  0.9072662 ,\n",
       "          3.2248068 ,  2.1934643 ],\n",
       "        [ 2.3475442 , -0.790759  ,  1.2707808 ,  1.3155396 ,\n",
       "          2.8450027 ,  1.4678874 ],\n",
       "        [ 1.338968  ,  0.        ,  0.5647262 ,  0.        ,\n",
       "          1.1797022 ,  0.12007414]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "embedded_inputs.node_features.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from msp.layers import GGCNLayer\n",
    "from msp.graphs import MSPSparseGraph\n",
    "from msp.solutions import MSPState\n",
    "\n",
    "class AttentionDecoder(Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 units,\n",
    "                 *args, \n",
    "                 activation='relu',\n",
    "                 aggregation_graph='mean',\n",
    "                 n_heads=8,\n",
    "                 **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        super(AttentionDecoder, self).__init__(*args, **kwargs)\n",
    "        self.aggregation_graph = aggregation_graph\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        embedding_dim = units\n",
    "        self.W_placeholder = self.add_weight(shape=(2*embedding_dim,),\n",
    "                                initializer='random_uniform', #Placeholder should be in range of activations (think)\n",
    "                                trainable=True)\n",
    "\n",
    "        graph_embed_shape = tf.TensorShape((None, units))\n",
    "        self.fixed_context_layer = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.fixed_context_layer.build(graph_embed_shape)\n",
    "\n",
    "        # For each node we compute (glimpse key, glimpse value, logit key) so 3 * embedding_dim\n",
    "        project_node_embeddings_shape = tf.TensorShape((None, None, None, units))\n",
    "        self.project_node_embeddings = tf.keras.layers.Dense(3*units, use_bias=False)\n",
    "        self.project_node_embeddings.build(project_node_embeddings_shape)\n",
    "\n",
    "        #\n",
    "        # Embedding of first and last node\n",
    "        step_context_dim = 2*units\n",
    "        project_step_context_shape = tf.TensorShape((None, None, step_context_dim))\n",
    "        self.project_step_context = tf.keras.layers.Dense(embedding_dim, use_bias=False)\n",
    "        self.project_step_context.build(project_step_context_shape)\n",
    "        \n",
    "        #nn.Linear(step_context_dim, embedding_dim, bias=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # self.context_layer = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        # self.mha_layer = None\n",
    "        \n",
    "\n",
    "        # dynamic router\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # self.initial_layer_1 = tf.keras.layers.Dense(units)\n",
    "        # self.initial_layer_2 = tf.keras.layers.Dense(units)\n",
    "        # self.ggcn_layers = [GGCNLayer(units, activation=activation)\n",
    "        #                     for _ in range(layers)]\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\" \"\"\"\n",
    "        state = MSPState(inputs)\n",
    "\n",
    "        node_embedding = inputs.node_embed\n",
    "\n",
    "        # AttentionModelFixed(node_embedding, fixed_context, *fixed_attention_node_data)\n",
    "        fixed = self._precompute(node_embedding)\n",
    "        return fixed \n",
    "\n",
    "        while not state.all_finished():\n",
    "\n",
    "            log_p, mask = self._get_log_p(fixed, state)\n",
    "\n",
    "        \n",
    "\n",
    "        node_embed = inputs.node_features\n",
    "        return self._get_parallel_step_context(node_embed)\n",
    "\n",
    "\n",
    "    def _precompute(self, node_embedding, num_steps=1):\n",
    "\n",
    "        graph_embed = self._get_graph_embed(node_embedding)\n",
    "\n",
    "        fixed_context = self.fixed_context_layer(graph_embed)\n",
    "        # fixed context = (batch_size, 1, embed_dim) to make broadcastable with parallel timesteps\n",
    "        fixed_context = tf.expand_dims(fixed_context, axis=-2)\n",
    "\n",
    "        glimpse_key_fixed, glimpse_val_fixed, logit_key_fixed  = tf.split(\n",
    "            self.project_node_embeddings(tf.expand_dims(node_embedding, axis=-3)),\n",
    "            num_or_size_splits=3,\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        return glimpse_key_fixed\n",
    "\n",
    "        # No need to rearrange key for logit as there is a single head\n",
    "        fixed_attention_node_data = (\n",
    "            self._make_heads(glimpse_key_fixed, num_steps),\n",
    "            self._make_heads(glimpse_val_fixed, num_steps),\n",
    "            logit_key_fixed\n",
    "        )\n",
    "        return AttentionModelFixed(node_embedding, fixed_context, *fixed_attention_node_data)\n",
    "\n",
    "    def _get_graph_embed(self, node_embedding):\n",
    "        \"\"\" \"\"\"\n",
    "        if self.aggregation_graph == \"sum\":\n",
    "            graph_embed = tf.reduce_sum(node_embedding, axis=-2)\n",
    "        elif self.aggregation_graph == \"max\":\n",
    "            graph_embed = tf.reduce_max(node_embedding, axis=-2)\n",
    "        elif self.aggregation_graph == \"mean\":\n",
    "            graph_embed = tf.reduce_mean(node_embedding, axis=-2)\n",
    "        else:  # Default: dissable graph embedding\n",
    "            graph_embed = tf.reduce_sum(node_embedding, axis=-2) * 0.0\n",
    "\n",
    "        return graph_embed\n",
    "\n",
    "    def _make_heads(self, v, num_steps=None):\n",
    "\n",
    "        assert num_steps is None or v.shape[1] == 1 or v.shape[1] == num_steps\n",
    "        \n",
    "        batch_size, _, num_nodes, embed_dims = v.shape\n",
    "        num_steps = num_steps if num_steps else 1\n",
    "\n",
    "        # M x B x N x V x H\n",
    "        return tf.broadcast_to(\n",
    "            tf.broadcast_to(v, shape=[batch_size, num_steps, num_nodes, embed_dims])[None,:,:,:,:],\n",
    "            shape=[self.n_heads, batch_size, num_steps, num_nodes, embed_dims]\n",
    "        )\n",
    "\n",
    "    def _get_log_p(self, fixed, state, normalize=True):\n",
    "        # Compute query = context node embedding\n",
    "        \n",
    "        # B x 1 x H\n",
    "        query = fixed.context_node_projected + \\\n",
    "                self.project_step_context(self._get_parallel_step_context(fixed.node_embeddings, state))\n",
    "        \n",
    "        # Compute keys and values for the nodes\n",
    "        glimpse_K, glimpse_V, logit_K = self._get_attention_node_data(fixed, state)\n",
    "\n",
    "        graph_mask = None\n",
    "        if self.mask_graph:\n",
    "            # Compute the graph mask, for masking next action based on graph structure \n",
    "            graph_mask = state.get_graph_mask()  # Pending...........................................\n",
    "\n",
    "        # Compute logits (unnormalized log_p)\n",
    "        log_p, glimpse = self._one_to_many_logits(query, glimpse_K, glimpse_V, logit_K, mask, graph_mask)\n",
    "        \n",
    "\n",
    "\n",
    "    def _get_parallel_step_context(self, node_embedding, state, from_depot=False):\n",
    "        \"\"\"\n",
    "        Returns the context per step, optionally for multiple steps at once \n",
    "        (for efficient evaluation of the model)\n",
    "        \"\"\"\n",
    "        current_node = state.get_current_node()\n",
    "        batch_size, num_steps = current_node.shape\n",
    "\n",
    "        if num_steps == 1:  # We need to special case if we have only 1 step, may be the first or not\n",
    "            if self.i.numpy()[0] == 0:\n",
    "                # First and only step, ignore prev_a (this is a placeholder)\n",
    "                # B x 1 x 2H\n",
    "                return tf.broadcast_to(self.W_placeholder[None, None, :], \n",
    "                                       shape=[batch_size, 1, self.W_placeholder.shape[-1]])\n",
    "                \n",
    "            # else:\n",
    "            #     return embeddings.gather(\n",
    "            #         1,\n",
    "            #         torch.cat((state.first_a, current_node), 1)[:, :, None].expand(batch_size, 2, embeddings.size(-1))\n",
    "            #     ).view(batch_size, 1, -1)\n",
    "\n",
    "    def _get_attention_node_data(self, fixed, state):\n",
    "        return fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key\n",
    "\n",
    "    def _one_to_many_logits(self, query, glimpse_K, glimpse_V, logit_K, mask, graph_mask=None):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.boolean_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('adj_matrix', 'node_features', 'edge_features', 'alpha')"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "MSPSparseGraph._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_sparse_data(4, msp_size=(1,2), random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSPSparseGraph(adj_matrix=<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [1., 0., 1.],\n",
       "       [1., 1., 0.]], dtype=float32)>, node_features=<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[0.27535218, 0.6795556 , 0.58162645, 0.97019879, 1.        ],\n",
       "       [0.33048907, 0.96671416, 0.82589904, 0.30540018, 1.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]])>, edge_features=<tf.Tensor: shape=(3, 3, 3), dtype=float64, numpy=\n",
       "array([[[0.        , 0.        , 0.        ],\n",
       "        [0.46459967, 0.12383996, 0.        ],\n",
       "        [0.        , 0.        , 1.        ]],\n",
       "\n",
       "       [[0.46459967, 0.12383996, 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 1.        ],\n",
       "        [0.        , 0.        , 1.        ],\n",
       "        [0.        , 0.        , 0.        ]]])>, alpha=<tf.Tensor: shape=(3, 1), dtype=float64, numpy=\n",
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.]])>)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "graph = list(dataset.take(1))[0]\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=int64, numpy=\n",
       "array([[0, 1],\n",
       "       [0, 2],\n",
       "       [1, 2],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [2, 1]])>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "indices= tf.cast(tf.transpose(\n",
    "    tf.concat([\n",
    "        edge_index,\n",
    "        tf.scatter_nd(\n",
    "            tf.constant([[1],[0]]),\n",
    "            edge_index,\n",
    "            edge_index.shape\n",
    "        )\n",
    "    ], axis=-1)\n",
    "), tf.int64)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7febac93e890>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "adj_matrix = tf.sparse.SparseTensor(\n",
    "    indices= indices,\n",
    "    values = tf.ones([2*edge_index.shape[-1]]),\n",
    "    dense_shape = [3,3]\n",
    ")\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [1., 0., 1.],\n",
       "       [1., 1., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sparse.reorder(adj_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "tf.ones([edge_index.shape[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Dimensions 3 and 2 are not compatible",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-7c983f92bf86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/sparse_tensor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, indices, values, dense_shape)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# Assert number of rows in indices match the number of elements in values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mindices_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Assert number of columns in indices matches the number of elements in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# dense_shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m       raise ValueError(\"Dimensions %s and %s are not compatible\" %\n\u001b[0;32m--> 289\u001b[0;31m                        (self, other))\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 3 and 2 are not compatible"
     ]
    }
   ],
   "source": [
    "E = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2], [2, 0]], values=[1, 2], dense_shape=[3, 4])\n",
    "tf.sparse.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "tf.ones((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GGCNLayer(Layer):\n",
    "\n",
    "    # @validate_hyperparams\n",
    "    def __init__(self, \n",
    "                 units,\n",
    "                 *args, \n",
    "                 activation='relu', \n",
    "                 use_bias=True, \n",
    "                 normalization='batch',\n",
    "                 aggregation='mean',\n",
    "                 **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        super(GGCNLayer, self).__init__(*args, **kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.normalization= normalization\n",
    "        self.aggregation = aggregation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Create the state of the layer (weights)\"\"\"\n",
    "        print('Build')\n",
    "        node_features_shape = input_shape.node_features\n",
    "        edge_featues_shape = input_shape.edge_features\n",
    "        embedded_shape = tf.TensorShape((None, self.units))\n",
    "\n",
    "        # _initial_projection_layer (think on it)\n",
    "\n",
    "        with tf.name_scope('node'):\n",
    "            with tf.name_scope('U'):\n",
    "                self.U = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.U.build(node_features_shape)\n",
    "\n",
    "            with tf.name_scope('V'):\n",
    "                self.V = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.V.build(node_features_shape)\n",
    "\n",
    "            with tf.name_scope('norm'):\n",
    "                self.norm_h = {\n",
    "                    \"batch\": tf.keras.layers.BatchNormalization(),\n",
    "                    \"layer\": tf.keras.layers.LayerNormalization()\n",
    "                }.get(self.normalization, None)\n",
    "                if self.norm_h:\n",
    "                    self.norm_h.build(embedded_shape)\n",
    "\n",
    "        with tf.name_scope('edge'):\n",
    "            with tf.name_scope('A'):\n",
    "                self.A = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.A.build(tf.TensorShape((None, node_features_shape[-1])))\n",
    "            \n",
    "            with tf.name_scope('B'):\n",
    "                self.B = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.B.build(node_features_shape)\n",
    "\n",
    "            with tf.name_scope('C'):\n",
    "                self.C = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.C.build(edge_featues_shape)\n",
    "\n",
    "            with tf.name_scope('norm'):\n",
    "                self.norm_e = {\n",
    "                    'batch': tf.keras.layers.BatchNormalization(),\n",
    "                    'layer': tf.keras.layers.LayerNormalization(axis=-2)\n",
    "                }.get(self.normalization, None)\n",
    "                if self.norm_e:\n",
    "                    self.norm_e.build(embedded_shape)\n",
    "    \n",
    "        super().build(input_shape)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        \"\"\" \"\"\"\n",
    "        print('call')\n",
    "        adj_matrix = inputs.adj_matrix\n",
    "        h = inputs.node_features\n",
    "        e = inputs.edge_features\n",
    "\n",
    "        # Edges Featuers\n",
    "        Ah = self.A(h)\n",
    "        Bh = self.B(h)\n",
    "        Ce = self.C(e)\n",
    "        e = self._update_edges(e, [Ah, Bh, Ce])\n",
    "\n",
    "        edge_gates = tf.sigmoid(e)\n",
    "\n",
    "        # Nodes Features\n",
    "        Uh = self.U(h)\n",
    "        Vh = self.V(h)\n",
    "        h = self._update_nodes(\n",
    "            h,\n",
    "            [Uh, self._aggregate(Vh, edge_gates, adj_matrix)]\n",
    "        )\n",
    "\n",
    "        outputs = MSPSparseGraph(adj_matrix, h, e, inputs.alpha)\n",
    "        return inputs\n",
    "        \n",
    "    def _update_edges(self, e, transformations:list):\n",
    "        \"\"\"Update edges features\"\"\"\n",
    "        Ah, Bh, Ce  = transformations\n",
    "        e_new = tf.expand_dims(Ah, axis=1) + tf.expand_dims(Bh, axis=2) + Ce\n",
    "        # Normalization\n",
    "        batch_size, num_nodes, num_nodes, hidden_dim = e_new.shape\n",
    "        if self.norm_e:\n",
    "            e_new = tf.reshape(\n",
    "                self.norm_e(\n",
    "                    tf.reshape(e_new, [batch_size*num_nodes*num_nodes, hidden_dim])\n",
    "                ), e_new.shape\n",
    "            )\n",
    "        # Activation\n",
    "        e_new = self.activation(e_new)\n",
    "        # Skip/residual Connection\n",
    "        e_new = e + e_new\n",
    "        return e_new\n",
    "\n",
    "    def _update_nodes(self, h, transformations:list):\n",
    "        \"\"\" \"\"\"\n",
    "        Uh, aggregated_messages = transformations\n",
    "        h_new = tf.math.add_n([Uh, aggregated_messages])\n",
    "        # Normalization\n",
    "        batch_size, num_nodes, hidden_dim = h_new.shape\n",
    "        if self.norm_h:\n",
    "            h_new = tf.reshape(\n",
    "                self.norm_h(\n",
    "                    tf.reshape(h_new, [batch_size*num_nodes, hidden_dim])\n",
    "                ), h_new.shape\n",
    "            )\n",
    "        # Activation\n",
    "        h_new = self.activation(h_new)\n",
    "        # Skip/residual Connection\n",
    "        h_new = h + h_new\n",
    "        return h_new\n",
    "\n",
    "    def _aggregate(self, Vh, edge_gates, adj_matrix):\n",
    "        \"\"\" \"\"\"\n",
    "        # Reshape as edge_gates\n",
    "        Vh = tf.broadcast_to(\n",
    "            tf.expand_dims(Vh, axis=1),\n",
    "            edge_gates.shape\n",
    "        )\n",
    "        # Gating mechanism\n",
    "        Vh = edge_gates * Vh\n",
    "        \n",
    "        # Enforce graph structure\n",
    "        # mask = tf.broadcast_to(tf.expand_dims(adj_matrix,axis=-1), Vh.shape)\n",
    "        # Vh[~mask] = 0\n",
    "\n",
    "        # message aggregation\n",
    "        if self.aggregation == 'mean':\n",
    "            total_messages = tf.cast(\n",
    "                tf.expand_dims(\n",
    "                    tf.math.reduce_sum(adj_matrix, axis=-1),\n",
    "                    axis=-1\n",
    "                ),\n",
    "                Vh.dtype\n",
    "            )\n",
    "            return tf.math.reduce_sum(Vh, axis=2) / total_messages\n",
    "        \n",
    "        elif self.aggregation == 'sum':\n",
    "            return tf.math.reduce_sum(Vh, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "B, V, H = 1, 3, 2\n",
    "h = tf.ones((B, V, H))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 3, 3]), TensorShape([2, 3, 3]))"
      ]
     },
     "metadata": {},
     "execution_count": 249
    }
   ],
   "source": [
    "dataset = make_sparse_data(4, msp_size=(1,2), random_state=2020)\n",
    "graphs = list(dataset.batch(2))\n",
    "VVh = list(graphs)[0].edge_features\n",
    "A = list(graphs)[0].adj_matrix\n",
    "VVh.shape, A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'GGCN_Layer/node/U/kernel:0' shape=(5, 3) dtype=float32, numpy=\n",
       " array([[ 0.3418128 , -0.74846673,  0.4793586 ],\n",
       "        [ 0.6570088 ,  0.8612539 ,  0.65150267],\n",
       "        [-0.72393733, -0.22281748, -0.22313446],\n",
       "        [ 0.79907125,  0.64225537, -0.03322494],\n",
       "        [ 0.555322  ,  0.38448828,  0.36000997]], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/node/U/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/node/V/kernel:0' shape=(5, 3) dtype=float32, numpy=\n",
       " array([[-0.26467794,  0.7648507 ,  0.719668  ],\n",
       "        [ 0.2005971 , -0.62737715, -0.5316253 ],\n",
       "        [-0.05412966, -0.2538466 , -0.8192339 ],\n",
       "        [ 0.02352881,  0.5495698 ,  0.2812906 ],\n",
       "        [ 0.08741534,  0.04532963,  0.46388656]], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/node/V/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/node/norm/gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/node/norm/beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/A/kernel:0' shape=(5, 3) dtype=float32, numpy=\n",
       " array([[ 0.09562737, -0.15982503,  0.17779714],\n",
       "        [-0.427093  , -0.42131868, -0.11058551],\n",
       "        [ 0.48724288, -0.16462517,  0.80764335],\n",
       "        [ 0.23215312, -0.20694935,  0.29836577],\n",
       "        [-0.26064217, -0.5128927 , -0.12195498]], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/A/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/B/kernel:0' shape=(5, 3) dtype=float32, numpy=\n",
       " array([[ 0.6643042 , -0.62542963,  0.67147344],\n",
       "        [ 0.8151302 , -0.8215904 ,  0.6337227 ],\n",
       "        [ 0.05792886, -0.6015081 , -0.45064723],\n",
       "        [ 0.43922204, -0.3565061 ,  0.02278858],\n",
       "        [ 0.5607044 ,  0.00907588, -0.40723762]], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/B/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/C/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[-0.31491876,  0.07352543, -0.8565612 ],\n",
       "        [-0.27666378, -0.7678697 , -0.76981115],\n",
       "        [ 0.59876394, -0.4960389 , -0.9064679 ]], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/C/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/norm/gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/norm/beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/node/norm/moving_mean:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/node/norm/moving_variance:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/norm/moving_mean:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'GGCN_Layer/edge/norm/moving_variance:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 252
    }
   ],
   "source": [
    "# mask = tf.cast(tf.broadcast_to(\n",
    "#     tf.expand_dims(A, axis=-1),\n",
    "#     VVh.shape\n",
    "# ), tf.bool)\n",
    "# VVh[~mask] \n",
    "ggcn.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Build\ncall\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [2,3,5] vs. [2,3,3] [Op:AddV2]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-dcf3b5c383d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mggcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGGCNLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GGCN_Layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mggcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-e873fb5543d1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         h = self._update_nodes(\n\u001b[1;32m    105\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mUh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_gates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-e873fb5543d1>\u001b[0m in \u001b[0;36m_update_nodes\u001b[0;34m(self, h, transformations)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mh_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Skip/residual Connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mh_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    521\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,3,5] vs. [2,3,3] [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "units = graphs[0].edge_features.shape[-1]\n",
    "ggcn = GGCNLayer(units=units, use_bias=True, name='GGCN_Layer')\n",
    "output = ggcn(graphs[0])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(\n",
    "    tf.expand_dims(\n",
    "        tf.math.reduce_sum(list(graphs)[0].adj_matrix, axis=-1),\n",
    "        axis=-1\n",
    "    ),\n",
    "    Vh.dtype\n",
    ")\n",
    "    tf.expand_dims(\n",
    "    tf.math.reduce_sum(list(graphs)[0].adj_matrix, axis=-1),\n",
    "    axis=-1).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       "array([[0.12417877, 0.31973648, 1.        ],\n",
       "       [0.12417877, 0.31973648, 1.        ],\n",
       "       [0.        , 0.        , 1.        ]])>"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "tf.math.reduce_max(graphs[0].edge_features, axis=-2 )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
       "array([[[0., 1., 1.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 1., 0.]],\n",
       "\n",
       "       [[0., 1., 1.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 1., 0.]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "list(graphs)[0].adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggcn = GGCNLayer(units=units, use_bias=True, name='GGCN_Layer')\n",
    "# output = ggcn(graphs[0])\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "graphs = list(make_data(1, msp_size=(1,2), random_state=2021).take(1))[0]\n",
    "\n",
    "num_edges = 3\n",
    "\n",
    "\n",
    "A = tf.sparse.SparseTensor(\n",
    "    indices= tf.cast(tf.transpose(graphs['edge_index']), tf.int64),\n",
    "    values = tf.ones([num_edges]),\n",
    "    dense_shape = [3,3]\n",
    ")\n",
    "\n",
    "tf.sparse.to_dense(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int64, numpy=\n",
       "array([[0, 1],\n",
       "       [0, 2],\n",
       "       [1, 2]])>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "tf.cast(tf.transpose(graphs['edge_index']), tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int64, numpy=\n",
       "array([[0, 1],\n",
       "       [0, 2],\n",
       "       [1, 2]])>"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "# ggcn.variables\n",
    "tf.cast(tf.transpose(graphs['edge_index']), tf.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [0, 2],\n",
       "       [1, 2],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [2, 1]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "edge_index = tf.cast(tf.transpose(\n",
    "    tf.concat([\n",
    "        graphs['edge_index'],\n",
    "        tf.scatter_nd(\n",
    "            tf.constant([[1],[0]]),\n",
    "            graphs['edge_index'],\n",
    "            graphs['edge_index'].shape\n",
    "        )\n",
    "    ], axis=-1)\n",
    "), tf.int32)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        self._build_graph_network_for_inferred_shape(inputs.shape, inputs.dtype)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:522 _method_wrapper\n        result = method(self, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:281 _build_graph_network_for_inferred_shape\n        input_shape = tuple(input_shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:868 __iter__\n        raise ValueError(\"Cannot iterate over a shape with unknown rank.\")\n\n    ValueError: Cannot iterate over a shape with unknown rank.\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-bc697979586f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m ])\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        self._build_graph_network_for_inferred_shape(inputs.shape, inputs.dtype)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:522 _method_wrapper\n        result = method(self, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:281 _build_graph_network_for_inferred_shape\n        input_shape = tuple(input_shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:868 __iter__\n        raise ValueError(\"Cannot iterate over a shape with unknown rank.\")\n\n    ValueError: Cannot iterate over a shape with unknown rank.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    GGCNLayer(units=units, use_bias=True, name='GGCN_Layer')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Weights for model sequential have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-dd9f7a7f3f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \"\"\"\n\u001b[0;32m-> 2446\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2449\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;34m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_tracked_trackables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m_assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# When the graph has not been initialized, use the Model's implementation to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;31m# to check if the weights has been created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=bad-super-call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2575\u001b[0m                        \u001b[0;34m'Weights are created when the Model is first called on '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2576\u001b[0m                        \u001b[0;34m'inputs or `build()` is called with an `input_shape`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2577\u001b[0;31m                        self.name)\n\u001b[0m\u001b[1;32m   2578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model sequential have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}