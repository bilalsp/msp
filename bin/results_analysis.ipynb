{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Required Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "EXPERIMENT_ID = '1005'\n",
    "\n",
    "experiment_dir = 'outputs/experiment_{}/'.format(EXPERIMENT_ID)\n",
    "results_path = experiment_dir + 'results.npy'\n",
    "schedules_path = experiment_dir + 'schedulesWithMakespan.npy'\n",
    "log_paths = glob.glob(experiment_dir + '*.log')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read log files, and results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# logs = pd.concat([pd.read_csv(log_file) for log_file in log_paths], axis=0)\n",
    "result_columns = ['batch_id', 'makespan_mean', 'cum_makespan_mean', 'time', 'cum_time']\n",
    "results = pd.DataFrame(np.load(results_path), columns=result_columns)\n",
    "with open(schedules_path, 'rb') as f:\n",
    "    batch_schedules = np.load(f)\n",
    "    batch_makespans = np.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def convert_schedules_np_to_df(batch_schedules, batch_makespans):\n",
    "    \"\"\"Convert batch schedules from numpy array to dataframe\"\"\"\n",
    "    n_batch_instance, batch_size, n_nodes, _ = batch_schedules.shape\n",
    "    schedules = batch_schedules.reshape((n_batch_instance*batch_size, n_nodes, 2))\n",
    "    # remove machine-to-machine pair\n",
    "    schedules = schedules[\n",
    "        np.not_equal(\n",
    "            schedules[:,:,:1], schedules[:,:,1:]\n",
    "        )[:,:,-1]\n",
    "    ].reshape(schedules.shape[0], -1, schedules.shape[-1]).astype(str)\n",
    "    \n",
    "    n_jobs = schedules.shape[1]\n",
    "    makespans = batch_makespans.reshape((n_batch_instance*batch_size,1))\n",
    "\n",
    "    df_schedules = pd.DataFrame(\n",
    "        np.concatenate([\n",
    "            np.apply_along_axis(\n",
    "                ' -> '.join, 0, [schedules[:,:,0], schedules[:,:,1]]),\n",
    "            makespans\n",
    "        ], axis=1),\n",
    "        columns= list(map(lambda v: \"J_\"+str(v), range(n_jobs)))+['makespan']\n",
    "       )\n",
    "    \n",
    "    return df_schedules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df_schedules = convert_schedules_np_to_df(batch_schedules, batch_makespans)\n",
    "df_schedules.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      J_0     J_1     J_2     J_3     J_4   makespan\n",
       "0  4 -> 5  3 -> 5  0 -> 5  2 -> 6  1 -> 6  2.3685446\n",
       "1  2 -> 5  3 -> 5  0 -> 5  4 -> 6  1 -> 6   2.329349\n",
       "2  1 -> 5  2 -> 5  0 -> 5  4 -> 6  3 -> 6  2.0618036\n",
       "3  3 -> 5  4 -> 5  2 -> 5  1 -> 6  0 -> 6  1.5268161\n",
       "4  1 -> 5  0 -> 5  4 -> 6  3 -> 6  2 -> 6  1.7808145\n",
       "5  3 -> 5  1 -> 5  0 -> 5  4 -> 6  2 -> 6   2.253179\n",
       "6  4 -> 5  3 -> 5  0 -> 5  2 -> 6  1 -> 6  1.4486477\n",
       "7  2 -> 5  1 -> 5  4 -> 6  0 -> 6  3 -> 6  1.6840694\n",
       "8  3 -> 5  2 -> 5  1 -> 6  4 -> 6  0 -> 6  1.0499716\n",
       "9  3 -> 5  2 -> 5  4 -> 6  0 -> 6  1 -> 6  1.8646028"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>J_0</th>\n",
       "      <th>J_1</th>\n",
       "      <th>J_2</th>\n",
       "      <th>J_3</th>\n",
       "      <th>J_4</th>\n",
       "      <th>makespan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>2.3685446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>2.329349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>2.0618036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>1.5268161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>1.7808145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>2.253179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>1.4486477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>1.6840694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>1.0499716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>1.8646028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "makespans.shape,  schedules.shape\n",
    "np.apply_along_axis(\n",
    "        ' -> '.join, 0, [schedules[:,:,0], schedules[:,:,1]]).shape\n",
    "\n",
    "np.concatenate([\n",
    "    np.apply_along_axis(\n",
    "        ' -> '.join, 0, [schedules[:,:,0], schedules[:,:,1]]),\n",
    "    makespans\n",
    "], axis=1)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['5 -> 5', '3 -> 5', '0 -> 5', '1 -> 5', '2 -> 5', '6 -> 6',\n",
       "        '4 -> 6', '4.1202216'],\n",
       "       ['5 -> 5', '0 -> 5', '1 -> 5', '6 -> 6', '3 -> 6', '4 -> 6',\n",
       "        '2 -> 6', '1.8093971'],\n",
       "       ['5 -> 5', '1 -> 5', '4 -> 5', '3 -> 5', '6 -> 6', '0 -> 6',\n",
       "        '2 -> 6', '2.050342'],\n",
       "       ['5 -> 5', '0 -> 5', '3 -> 5', '4 -> 5', '6 -> 6', '1 -> 6',\n",
       "        '2 -> 6', '3.4389796'],\n",
       "       ['5 -> 5', '2 -> 5', '0 -> 5', '1 -> 5', '4 -> 5', '3 -> 5',\n",
       "        '6 -> 6', '4.6745625'],\n",
       "       ['5 -> 5', '1 -> 5', '6 -> 6', '3 -> 6', '4 -> 6', '0 -> 6',\n",
       "        '2 -> 6', '3.0054615'],\n",
       "       ['5 -> 5', '2 -> 5', '3 -> 5', '0 -> 5', '1 -> 5', '4 -> 5',\n",
       "        '6 -> 6', '5.427072'],\n",
       "       ['5 -> 5', '1 -> 5', '3 -> 5', '2 -> 5', '4 -> 5', '6 -> 6',\n",
       "        '0 -> 6', '3.291935'],\n",
       "       ['5 -> 5', '4 -> 5', '3 -> 5', '0 -> 5', '2 -> 5', '1 -> 5',\n",
       "        '6 -> 6', '6.268305'],\n",
       "       ['5 -> 5', '1 -> 5', '6 -> 6', '3 -> 6', '0 -> 6', '2 -> 6',\n",
       "        '4 -> 6', '3.5240579'],\n",
       "       ['5 -> 5', '0 -> 5', '1 -> 5', '3 -> 5', '6 -> 6', '2 -> 6',\n",
       "        '4 -> 6', '2.022379'],\n",
       "       ['5 -> 5', '4 -> 5', '3 -> 5', '0 -> 5', '6 -> 6', '1 -> 6',\n",
       "        '2 -> 6', '2.9663215'],\n",
       "       ['5 -> 5', '3 -> 5', '1 -> 5', '6 -> 6', '2 -> 6', '0 -> 6',\n",
       "        '4 -> 6', '2.97403'],\n",
       "       ['5 -> 5', '4 -> 5', '2 -> 5', '0 -> 5', '6 -> 6', '3 -> 6',\n",
       "        '1 -> 6', '1.9081707'],\n",
       "       ['5 -> 5', '2 -> 5', '1 -> 5', '3 -> 5', '6 -> 6', '4 -> 6',\n",
       "        '0 -> 6', '1.6280885'],\n",
       "       ['5 -> 5', '4 -> 5', '2 -> 5', '3 -> 5', '6 -> 6', '1 -> 6',\n",
       "        '0 -> 6', '3.7251925'],\n",
       "       ['5 -> 5', '2 -> 5', '1 -> 5', '4 -> 5', '3 -> 5', '6 -> 6',\n",
       "        '0 -> 6', '4.695125'],\n",
       "       ['5 -> 5', '0 -> 5', '6 -> 6', '4 -> 6', '3 -> 6', '2 -> 6',\n",
       "        '1 -> 6', '4.4765887'],\n",
       "       ['5 -> 5', '4 -> 5', '6 -> 6', '1 -> 6', '2 -> 6', '0 -> 6',\n",
       "        '3 -> 6', '3.2056866'],\n",
       "       ['5 -> 5', '0 -> 5', '6 -> 6', '2 -> 6', '3 -> 6', '4 -> 6',\n",
       "        '1 -> 6', '3.1705523'],\n",
       "       ['5 -> 5', '3 -> 5', '1 -> 5', '2 -> 5', '6 -> 6', '0 -> 6',\n",
       "        '4 -> 6', '3.486442'],\n",
       "       ['5 -> 5', '1 -> 5', '0 -> 5', '3 -> 5', '6 -> 6', '2 -> 6',\n",
       "        '4 -> 6', '3.0442905'],\n",
       "       ['5 -> 5', '4 -> 5', '0 -> 5', '6 -> 6', '2 -> 6', '1 -> 6',\n",
       "        '3 -> 6', '2.5101833'],\n",
       "       ['5 -> 5', '2 -> 5', '3 -> 5', '6 -> 6', '0 -> 6', '4 -> 6',\n",
       "        '1 -> 6', '2.1588836'],\n",
       "       ['5 -> 5', '3 -> 5', '6 -> 6', '1 -> 6', '2 -> 6', '0 -> 6',\n",
       "        '4 -> 6', '2.9759874'],\n",
       "       ['5 -> 5', '0 -> 5', '1 -> 5', '2 -> 5', '6 -> 6', '3 -> 6',\n",
       "        '4 -> 6', '1.4730709'],\n",
       "       ['5 -> 5', '1 -> 5', '0 -> 5', '6 -> 6', '4 -> 6', '3 -> 6',\n",
       "        '2 -> 6', '2.977961'],\n",
       "       ['5 -> 5', '1 -> 5', '3 -> 5', '0 -> 5', '6 -> 6', '4 -> 6',\n",
       "        '2 -> 6', '2.5275483'],\n",
       "       ['5 -> 5', '4 -> 5', '3 -> 5', '6 -> 6', '2 -> 6', '0 -> 6',\n",
       "        '1 -> 6', '2.4707196'],\n",
       "       ['5 -> 5', '3 -> 5', '6 -> 6', '2 -> 6', '1 -> 6', '4 -> 6',\n",
       "        '0 -> 6', '2.7855203'],\n",
       "       ['5 -> 5', '0 -> 5', '2 -> 5', '6 -> 6', '3 -> 6', '1 -> 6',\n",
       "        '4 -> 6', '3.2157311'],\n",
       "       ['5 -> 5', '3 -> 5', '4 -> 5', '6 -> 6', '2 -> 6', '1 -> 6',\n",
       "        '0 -> 6', '2.393405'],\n",
       "       ['5 -> 5', '0 -> 5', '2 -> 5', '6 -> 6', '1 -> 6', '4 -> 6',\n",
       "        '3 -> 6', '2.962733'],\n",
       "       ['5 -> 5', '3 -> 5', '6 -> 6', '0 -> 6', '4 -> 6', '2 -> 6',\n",
       "        '1 -> 6', '4.4704065'],\n",
       "       ['5 -> 5', '2 -> 5', '6 -> 6', '1 -> 6', '0 -> 6', '4 -> 6',\n",
       "        '3 -> 6', '3.3364108'],\n",
       "       ['5 -> 5', '3 -> 5', '2 -> 5', '6 -> 6', '4 -> 6', '1 -> 6',\n",
       "        '0 -> 6', '1.8417923'],\n",
       "       ['5 -> 5', '4 -> 5', '0 -> 5', '2 -> 5', '3 -> 5', '6 -> 6',\n",
       "        '1 -> 6', '3.9044058'],\n",
       "       ['5 -> 5', '3 -> 5', '4 -> 5', '1 -> 5', '6 -> 6', '0 -> 6',\n",
       "        '2 -> 6', '2.5286293'],\n",
       "       ['5 -> 5', '0 -> 5', '1 -> 5', '2 -> 5', '6 -> 6', '3 -> 6',\n",
       "        '4 -> 6', '2.6631856'],\n",
       "       ['5 -> 5', '4 -> 5', '2 -> 5', '1 -> 5', '6 -> 6', '0 -> 6',\n",
       "        '3 -> 6', '3.4287446'],\n",
       "       ['5 -> 5', '4 -> 5', '3 -> 5', '1 -> 5', '0 -> 5', '2 -> 5',\n",
       "        '6 -> 6', '4.5789757'],\n",
       "       ['5 -> 5', '1 -> 5', '6 -> 6', '2 -> 6', '3 -> 6', '4 -> 6',\n",
       "        '0 -> 6', '2.829761'],\n",
       "       ['5 -> 5', '6 -> 6', '3 -> 6', '1 -> 6', '4 -> 6', '0 -> 6',\n",
       "        '2 -> 6', '3.2408855'],\n",
       "       ['5 -> 5', '2 -> 5', '3 -> 5', '0 -> 5', '6 -> 6', '1 -> 6',\n",
       "        '4 -> 6', '2.1371822'],\n",
       "       ['5 -> 5', '0 -> 5', '1 -> 5', '3 -> 5', '6 -> 6', '2 -> 6',\n",
       "        '4 -> 6', '3.107292'],\n",
       "       ['5 -> 5', '1 -> 5', '0 -> 5', '4 -> 5', '6 -> 6', '2 -> 6',\n",
       "        '3 -> 6', '3.1559463'],\n",
       "       ['5 -> 5', '4 -> 5', '6 -> 6', '2 -> 6', '0 -> 6', '1 -> 6',\n",
       "        '3 -> 6', '4.6642294'],\n",
       "       ['5 -> 5', '4 -> 5', '3 -> 5', '1 -> 5', '6 -> 6', '0 -> 6',\n",
       "        '2 -> 6', '1.9639966'],\n",
       "       ['5 -> 5', '1 -> 5', '2 -> 5', '6 -> 6', '4 -> 6', '0 -> 6',\n",
       "        '3 -> 6', '1.10884'],\n",
       "       ['5 -> 5', '1 -> 5', '2 -> 5', '0 -> 5', '4 -> 5', '3 -> 5',\n",
       "        '6 -> 6', '5.8251715'],\n",
       "       ['5 -> 5', '4 -> 5', '3 -> 5', '6 -> 6', '1 -> 6', '2 -> 6',\n",
       "        '0 -> 6', '1.8006896'],\n",
       "       ['5 -> 5', '3 -> 5', '4 -> 5', '6 -> 6', '2 -> 6', '1 -> 6',\n",
       "        '0 -> 6', '2.9565463'],\n",
       "       ['5 -> 5', '3 -> 5', '4 -> 5', '1 -> 5', '6 -> 6', '0 -> 6',\n",
       "        '2 -> 6', '3.0925565'],\n",
       "       ['5 -> 5', '6 -> 6', '2 -> 6', '4 -> 6', '1 -> 6', '0 -> 6',\n",
       "        '3 -> 6', '4.707913'],\n",
       "       ['5 -> 5', '3 -> 5', '2 -> 5', '4 -> 5', '0 -> 5', '6 -> 6',\n",
       "        '1 -> 6', '3.2371082'],\n",
       "       ['5 -> 5', '3 -> 5', '2 -> 5', '1 -> 5', '6 -> 6', '0 -> 6',\n",
       "        '4 -> 6', '2.5874734'],\n",
       "       ['5 -> 5', '0 -> 5', '1 -> 5', '6 -> 6', '2 -> 6', '3 -> 6',\n",
       "        '4 -> 6', '2.0222511'],\n",
       "       ['5 -> 5', '0 -> 5', '6 -> 6', '4 -> 6', '2 -> 6', '3 -> 6',\n",
       "        '1 -> 6', '2.6876419'],\n",
       "       ['5 -> 5', '1 -> 5', '6 -> 6', '3 -> 6', '2 -> 6', '4 -> 6',\n",
       "        '0 -> 6', '3.3015466'],\n",
       "       ['5 -> 5', '6 -> 6', '0 -> 6', '4 -> 6', '2 -> 6', '3 -> 6',\n",
       "        '1 -> 6', '1.8668945'],\n",
       "       ['5 -> 5', '3 -> 5', '2 -> 5', '6 -> 6', '0 -> 6', '1 -> 6',\n",
       "        '4 -> 6', '2.3066711'],\n",
       "       ['5 -> 5', '2 -> 5', '4 -> 5', '1 -> 5', '6 -> 6', '3 -> 6',\n",
       "        '0 -> 6', '2.3086023'],\n",
       "       ['5 -> 5', '2 -> 5', '3 -> 5', '0 -> 5', '6 -> 6', '1 -> 6',\n",
       "        '4 -> 6', '2.3543978'],\n",
       "       ['5 -> 5', '4 -> 5', '2 -> 5', '6 -> 6', '1 -> 6', '0 -> 6',\n",
       "        '3 -> 6', '2.7040875']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "#\"V_\".join(list(range(n_nodes)))\n",
    "\n",
    "list(map(lambda v: \"V_\"+str(v), range(1,n_nodes+1)))+['makespan']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['V_1', 'V_2', 'V_3', 'V_4', 'V_5', 'V_6', 'V_7', 'makespan']"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "\"V_\".join(map(str, range(1, n_nodes+1)))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1V_2V_3V_4V_5V_6V_7'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       V_0     V_1     V_2     V_3     V_4     V_5     V_6   makespan\n",
       "0   5 -> 5  3 -> 5  0 -> 5  1 -> 5  2 -> 5  6 -> 6  4 -> 6  4.1202216\n",
       "1   5 -> 5  0 -> 5  1 -> 5  6 -> 6  3 -> 6  4 -> 6  2 -> 6  1.8093971\n",
       "2   5 -> 5  1 -> 5  4 -> 5  3 -> 5  6 -> 6  0 -> 6  2 -> 6   2.050342\n",
       "3   5 -> 5  0 -> 5  3 -> 5  4 -> 5  6 -> 6  1 -> 6  2 -> 6  3.4389796\n",
       "4   5 -> 5  2 -> 5  0 -> 5  1 -> 5  4 -> 5  3 -> 5  6 -> 6  4.6745625\n",
       "..     ...     ...     ...     ...     ...     ...     ...        ...\n",
       "59  5 -> 5  6 -> 6  0 -> 6  4 -> 6  2 -> 6  3 -> 6  1 -> 6  1.8668945\n",
       "60  5 -> 5  3 -> 5  2 -> 5  6 -> 6  0 -> 6  1 -> 6  4 -> 6  2.3066711\n",
       "61  5 -> 5  2 -> 5  4 -> 5  1 -> 5  6 -> 6  3 -> 6  0 -> 6  2.3086023\n",
       "62  5 -> 5  2 -> 5  3 -> 5  0 -> 5  6 -> 6  1 -> 6  4 -> 6  2.3543978\n",
       "63  5 -> 5  4 -> 5  2 -> 5  6 -> 6  1 -> 6  0 -> 6  3 -> 6  2.7040875\n",
       "\n",
       "[64 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_0</th>\n",
       "      <th>V_1</th>\n",
       "      <th>V_2</th>\n",
       "      <th>V_3</th>\n",
       "      <th>V_4</th>\n",
       "      <th>V_5</th>\n",
       "      <th>V_6</th>\n",
       "      <th>makespan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>4.1202216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>1.8093971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>2.050342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>3.4389796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>4.6745625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>1.8668945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>2.3066711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>2.3086023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>2.3543978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>2.7040875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "makespans.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "batch_makespans"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[4.1202216],\n",
       "        [1.8093971],\n",
       "        [2.050342 ],\n",
       "        [3.4389796]],\n",
       "\n",
       "       [[4.6745625],\n",
       "        [3.0054615],\n",
       "        [5.427072 ],\n",
       "        [3.291935 ]],\n",
       "\n",
       "       [[6.268305 ],\n",
       "        [3.5240579],\n",
       "        [2.022379 ],\n",
       "        [2.9663215]],\n",
       "\n",
       "       [[2.97403  ],\n",
       "        [1.9081707],\n",
       "        [1.6280885],\n",
       "        [3.7251925]],\n",
       "\n",
       "       [[4.695125 ],\n",
       "        [4.4765887],\n",
       "        [3.2056866],\n",
       "        [3.1705523]],\n",
       "\n",
       "       [[3.486442 ],\n",
       "        [3.0442905],\n",
       "        [2.5101833],\n",
       "        [2.1588836]],\n",
       "\n",
       "       [[2.9759874],\n",
       "        [1.4730709],\n",
       "        [2.977961 ],\n",
       "        [2.5275483]],\n",
       "\n",
       "       [[2.4707196],\n",
       "        [2.7855203],\n",
       "        [3.2157311],\n",
       "        [2.393405 ]],\n",
       "\n",
       "       [[2.962733 ],\n",
       "        [4.4704065],\n",
       "        [3.3364108],\n",
       "        [1.8417923]],\n",
       "\n",
       "       [[3.9044058],\n",
       "        [2.5286293],\n",
       "        [2.6631856],\n",
       "        [3.4287446]],\n",
       "\n",
       "       [[4.5789757],\n",
       "        [2.829761 ],\n",
       "        [3.2408855],\n",
       "        [2.1371822]],\n",
       "\n",
       "       [[3.107292 ],\n",
       "        [3.1559463],\n",
       "        [4.6642294],\n",
       "        [1.9639966]],\n",
       "\n",
       "       [[1.10884  ],\n",
       "        [5.8251715],\n",
       "        [1.8006896],\n",
       "        [2.9565463]],\n",
       "\n",
       "       [[3.0925565],\n",
       "        [4.707913 ],\n",
       "        [3.2371082],\n",
       "        [2.5874734]],\n",
       "\n",
       "       [[2.0222511],\n",
       "        [2.6876419],\n",
       "        [3.3015466],\n",
       "        [1.8668945]],\n",
       "\n",
       "       [[2.3066711],\n",
       "        [2.3086023],\n",
       "        [2.3543978],\n",
       "        [2.7040875]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# r = best_schedules.reshape((64, 7, 2))\n",
    "# #np.transpose(r, (0,2,1))\n",
    "# r = r.astype(str)\n",
    "\n",
    "# r[:,:,0]#  + \",\" + r[:,:,1] \n",
    "\n",
    "# #np.core.defchararray.add(r[:,:,0], r[:,:,1])\n",
    "\n",
    "# # list(zip(r[:,:,0], r[:,:,1]))\n",
    "\n",
    "# # numpy.char.join(r[:,:,0], r[:,:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0       1       2       3       4       5       6\n",
       "0   5 -> 5  3 -> 5  0 -> 5  1 -> 5  2 -> 5  6 -> 6  4 -> 6\n",
       "1   5 -> 5  0 -> 5  1 -> 5  6 -> 6  3 -> 6  4 -> 6  2 -> 6\n",
       "2   5 -> 5  1 -> 5  4 -> 5  3 -> 5  6 -> 6  0 -> 6  2 -> 6\n",
       "3   5 -> 5  0 -> 5  3 -> 5  4 -> 5  6 -> 6  1 -> 6  2 -> 6\n",
       "4   5 -> 5  2 -> 5  0 -> 5  1 -> 5  4 -> 5  3 -> 5  6 -> 6\n",
       "..     ...     ...     ...     ...     ...     ...     ...\n",
       "59  5 -> 5  6 -> 6  0 -> 6  4 -> 6  2 -> 6  3 -> 6  1 -> 6\n",
       "60  5 -> 5  3 -> 5  2 -> 5  6 -> 6  0 -> 6  1 -> 6  4 -> 6\n",
       "61  5 -> 5  2 -> 5  4 -> 5  1 -> 5  6 -> 6  3 -> 6  0 -> 6\n",
       "62  5 -> 5  2 -> 5  3 -> 5  0 -> 5  6 -> 6  1 -> 6  4 -> 6\n",
       "63  5 -> 5  4 -> 5  2 -> 5  6 -> 6  1 -> 6  0 -> 6  3 -> 6\n",
       "\n",
       "[64 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "      <td>2 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>1 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>3 -&gt; 5</td>\n",
       "      <td>0 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>4 -&gt; 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5 -&gt; 5</td>\n",
       "      <td>4 -&gt; 5</td>\n",
       "      <td>2 -&gt; 5</td>\n",
       "      <td>6 -&gt; 6</td>\n",
       "      <td>1 -&gt; 6</td>\n",
       "      <td>0 -&gt; 6</td>\n",
       "      <td>3 -&gt; 6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "#best_makespans.shape, \n",
    "\n",
    "a = np.arange(6).reshape((3, 2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.chararray((3, 3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "path = 'outputs/experiment_{}/schedulesWithMakespan.npy'.format(experiment_id)\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    best_schedules = np.load(f)\n",
    "    best_makespans = np.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "path = 'outputs/experiment_{}/results.npy'.format(experiment_id)\n",
    "with open(path, 'rb') as f:\n",
    "    results = np.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "log_path = 'outputs/experiment_{}/results.npy'.format(experiment_id)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "_columns = ['batch_id', 'makespan_mean', 'cum_makespan_mean', 'time', 'cum_time']\n",
    "df = pd.DataFrame(results, columns=_columns)\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   batch_id  makespan_mean  cum_makespan_mean      time  cum_time\n",
       "0       0.0       3.189371           3.189371  0.016163  0.117919\n",
       "1       1.0       3.750617           3.469994  0.017083  0.159562\n",
       "2       2.0       2.911465           3.283818  0.016928  0.201338\n",
       "3       3.0       2.761600           3.153264  0.016646  0.242393"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>makespan_mean</th>\n",
       "      <th>cum_makespan_mean</th>\n",
       "      <th>time</th>\n",
       "      <th>cum_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.189371</td>\n",
       "      <td>3.189371</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>0.117919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.750617</td>\n",
       "      <td>3.469994</td>\n",
       "      <td>0.017083</td>\n",
       "      <td>0.159562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.911465</td>\n",
       "      <td>3.283818</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.201338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.761600</td>\n",
       "      <td>3.153264</td>\n",
       "      <td>0.016646</td>\n",
       "      <td>0.242393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modules: Datasets and Graphs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from msp.datasets import make_data, load_sample_data, make_sparse_data\n",
    "from msp.graphs import MSPGraph, MSPSparseGraph\n",
    "from msp.models.encoders import GGCNEncoder\n",
    "from msp.models.decoders import AttentionDecoder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset = make_sparse_data(40, msp_size=(2,5), random_state=2021)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "type_ = tf.constant([[[4,3,6,1]],[[9,3,6,1]]])\n",
    "\n",
    "# tf.slice(type_, [0,0,2], [-1,-1,-1])\n",
    "temp = tf.zeros(type_.shape)\n",
    "cur_node = tf.constant([[2],[1]])\n",
    "tf.tensor_scatter_nd_update(temp, indices, [1,1])\n",
    "\n",
    "\n",
    "\n",
    "self._visited = tf.tensor_scatter_nd_update(\n",
    "    tf.squeeze(temp, axis=-2),\n",
    "    tf.concat([tf.reshape(tf.range(batch_size, dtype=tf.int64),cur_node.shape), cur_node], axis=1),\n",
    "    tf.ones((batch_size,), dtype=self._visited.dtype)\n",
    ")[:,tf.newaxis,:]\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "Inner dimensions of output shape must match inner dimensions of updates shape. Output: [2,1,4] updates: [2] [Op:TensorScatterUpdate]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-708d5a29a087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_scatter_nd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtensor_scatter_nd_update\u001b[0;34m(tensor, indices, updates, name)\u001b[0m\n\u001b[1;32m   5727\u001b[0m   \"\"\"\n\u001b[1;32m   5728\u001b[0m   return gen_array_ops.tensor_scatter_update(\n\u001b[0;32m-> 5729\u001b[0;31m       tensor=tensor, indices=indices, updates=updates, name=name)\n\u001b[0m\u001b[1;32m   5730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtensor_scatter_update\u001b[0;34m(tensor, indices, updates, name)\u001b[0m\n\u001b[1;32m  11297\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11298\u001b[0m       return tensor_scatter_update_eager_fallback(\n\u001b[0;32m> 11299\u001b[0;31m           tensor, indices, updates, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m  11300\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11301\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtensor_scatter_update_eager_fallback\u001b[0;34m(tensor, indices, updates, name, ctx)\u001b[0m\n\u001b[1;32m  11324\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tindices\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11325\u001b[0m   _result = _execute.execute(b\"TensorScatterUpdate\", 1, inputs=_inputs_flat,\n\u001b[0;32m> 11326\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m  11327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11328\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Inner dimensions of output shape must match inner dimensions of updates shape. Output: [2,1,4] updates: [2] [Op:TensorScatterUpdate]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "indices = tf.constant([[2],[1]])\n",
    "tf.gather(tf.squeeze(type_), indices, batch_dims=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
       "array([[6],\n",
       "       [3]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tf.squeeze(type_)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([2, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "batch_size = 2\n",
    "batch_dataset = dataset.batch(batch_size)\n",
    "inputs = list(batch_dataset.take(1))[0]\n",
    "inputs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSPSparseGraph(msp_size=<tf.Tensor: shape=(2, 2), dtype=uint8, numpy=\n",
       "array([[2, 5],\n",
       "       [2, 5]], dtype=uint8)>, adj_matrix=<tf.Tensor: shape=(2, 7, 7), dtype=uint8, numpy=\n",
       "array([[[0, 1, 1, 0, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 0, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0]],\n",
       "\n",
       "       [[0, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0]]], dtype=uint8)>, node_features=<tf.Tensor: shape=(2, 7, 5), dtype=float64, numpy=\n",
       "array([[[0.60597828, 0.73336936, 0.13894716, 0.31267308, 1.        ],\n",
       "        [0.12816238, 0.17899311, 0.75292543, 0.66216051, 1.        ],\n",
       "        [0.0968944 , 0.05857129, 0.96239599, 0.61655744, 1.        ],\n",
       "        [0.56127236, 0.61652471, 0.96384302, 0.57430429, 1.        ],\n",
       "        [0.45214524, 0.20185025, 0.56930512, 0.19509597, 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.2306982 , 0.70481743, 0.71764771, 0.1482483 , 1.        ],\n",
       "        [0.80261811, 0.81018863, 0.7960028 , 0.85798945, 1.        ],\n",
       "        [0.15884363, 0.68614311, 0.73354523, 0.14800568, 1.        ],\n",
       "        [0.38240705, 0.50355847, 0.65716279, 0.75192426, 1.        ],\n",
       "        [0.21096367, 0.67407346, 0.89722956, 0.7621149 , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]])>, edge_features=<tf.Tensor: shape=(2, 7, 7, 3), dtype=float64, numpy=\n",
       "array([[[[0.        , 0.        , 0.        ],\n",
       "         [0.34220895, 0.82379121, 0.        ],\n",
       "         [0.30754346, 0.20132266, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.65092373, 0.15461481, 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.34220895, 0.82379121, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.4738473 , 0.79864132, 0.        ],\n",
       "         [0.87455684, 0.77697688, 0.        ],\n",
       "         [0.06310333, 0.59443849, 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.30754346, 0.20132266, 0.        ],\n",
       "         [0.4738473 , 0.79864132, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.32089874, 0.37229636, 0.        ],\n",
       "         [0.67955559, 0.58162647, 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.87455684, 0.77697688, 0.        ],\n",
       "         [0.32089874, 0.37229636, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.55691046, 0.71850103, 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.65092373, 0.15461481, 0.        ],\n",
       "         [0.06310333, 0.59443849, 0.        ],\n",
       "         [0.67955559, 0.58162647, 0.        ],\n",
       "         [0.55691046, 0.71850103, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.61510634, 0.7362588 , 0.        ],\n",
       "         [0.60954094, 0.06232428, 0.        ],\n",
       "         [0.42825156, 0.41746134, 0.        ],\n",
       "         [0.76197428, 0.01860237, 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.61510634, 0.7362588 , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.53669   , 0.607032  , 0.        ],\n",
       "         [0.30372581, 0.67145324, 0.        ],\n",
       "         [0.24000667, 0.48336405, 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.60954094, 0.06232428, 0.        ],\n",
       "         [0.53669   , 0.607032  , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.73850632, 0.74905211, 0.        ],\n",
       "         [0.34287274, 0.0050395 , 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.42825156, 0.41746134, 0.        ],\n",
       "         [0.30372581, 0.67145324, 0.        ],\n",
       "         [0.73850632, 0.74905211, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.0087207 , 0.16813959, 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.76197428, 0.01860237, 0.        ],\n",
       "         [0.24000667, 0.48336405, 0.        ],\n",
       "         [0.34287274, 0.0050395 , 0.        ],\n",
       "         [0.0087207 , 0.16813959, 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]]])>, alpha=<tf.Tensor: shape=(2, 7, 2), dtype=float64, numpy=\n",
       "array([[[1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]])>)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modules: Layers and Encoders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "units = 6\n",
    "layers = 2\n",
    "ecoder_model = GGCNEncoder(units, layers)\n",
    "embedded_inputs = ecoder_model(inputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "embedded_inputs.node_embed"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 7, 6), dtype=float32, numpy=\n",
       "array([[[-1.4382148e-01,  9.6293068e-01,  2.6263008e+00,  8.1934345e-01,\n",
       "         -8.5672736e-02,  5.8940428e-01],\n",
       "        [ 3.0298412e-02,  1.6358614e+00,  1.6347841e+00,  3.6575854e-02,\n",
       "          1.5360398e+00,  1.0922415e+00],\n",
       "        [ 1.7571726e-01,  1.7597905e+00,  1.7030218e+00, -6.0753770e-02,\n",
       "          1.6991560e+00,  1.3841438e+00],\n",
       "        [ 3.7202388e-02,  1.2748857e+00,  1.8815839e+00,  1.7817324e-01,\n",
       "          6.8495989e-01,  9.9834001e-01],\n",
       "        [ 3.0412453e-01,  5.2222323e-01,  1.6923902e+00,  5.4357314e-01,\n",
       "          3.6024973e-01,  3.4970191e-01],\n",
       "        [ 1.7666927e-01,  2.9611260e-01,  1.0662408e+00,  6.4383304e-01,\n",
       "          2.4254315e-01,  0.0000000e+00],\n",
       "        [ 1.7666927e-01,  2.9611260e-01,  1.0662408e+00,  6.4383304e-01,\n",
       "          2.4254315e-01,  0.0000000e+00]],\n",
       "\n",
       "       [[ 1.6468465e-03,  1.0810244e+00,  2.1540470e+00,  6.9013402e-02,\n",
       "          1.8178177e-01,  8.9684927e-01],\n",
       "        [-1.2560275e-01,  1.2845418e+00,  1.7040696e+00,  3.1247854e-01,\n",
       "          7.1645355e-01,  1.3736874e+00],\n",
       "        [-1.2822419e-02,  1.1132600e+00,  2.1513920e+00,  3.3307523e-02,\n",
       "          2.4248376e-01,  9.3204880e-01],\n",
       "        [-7.3153138e-02,  1.4145074e+00,  1.7559361e+00,  2.2578964e-01,\n",
       "          1.0818201e+00,  1.1742004e+00],\n",
       "        [-2.0713151e-01,  1.8382325e+00,  1.9194335e+00,  2.5290596e-01,\n",
       "          1.2314630e+00,  1.5690231e+00],\n",
       "        [ 2.4758640e-01,  1.6265145e-01,  1.3004950e+00,  5.6970334e-01,\n",
       "          0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.4758640e-01,  1.6265145e-01,  1.3004950e+00,  5.6970334e-01,\n",
       "          0.0000000e+00,  0.0000000e+00]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "embedded_inputs.edge_embed"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 7, 7, 6), dtype=float32, numpy=\n",
       "array([[[[ 2.50189126e-01,  1.01695740e+00,  6.23385191e-01,\n",
       "           8.16367984e-01,  6.22225940e-01,  4.46099967e-01],\n",
       "         [ 1.16019940e+00,  1.72448909e+00,  3.93749446e-01,\n",
       "           3.10133249e-01, -5.01590371e-01,  5.63548148e-01],\n",
       "         [ 1.43835652e+00,  2.24321032e+00,  5.32857537e-01,\n",
       "          -7.28480518e-04, -1.19393364e-01,  1.77944869e-01],\n",
       "         [ 7.98115373e-01,  1.17682934e+00,  8.40444684e-01,\n",
       "           5.86094320e-01,  6.14124000e-01,  1.51605129e-01],\n",
       "         [ 1.12041509e+00,  1.64951026e+00,  6.24807000e-01,\n",
       "          -1.42291248e-01, -1.41600370e-01,  6.89730287e-01],\n",
       "         [-3.71431917e-01,  4.45764840e-01,  9.94485259e-01,\n",
       "           1.86788011e+00,  1.60849881e+00, -1.35840312e-01],\n",
       "         [-3.71431917e-01,  4.45764840e-01,  9.94485259e-01,\n",
       "           1.86788011e+00,  1.60849881e+00, -1.35840312e-01]],\n",
       "\n",
       "        [[ 1.29513764e+00,  1.03694320e+00,  4.34905380e-01,\n",
       "           1.72726357e+00, -5.20441949e-01,  5.63548148e-01],\n",
       "         [ 2.08042669e+00,  1.55596673e+00,  4.42917645e-01,\n",
       "           5.97647250e-01,  0.00000000e+00,  7.55439997e-02],\n",
       "         [ 2.64860559e+00,  1.67726362e+00,  4.03944999e-01,\n",
       "           2.52108246e-01, -5.15189767e-01,  5.71866453e-01],\n",
       "         [ 2.88822675e+00,  1.64601994e+00,  6.59759283e-01,\n",
       "           1.14169165e-01, -5.32173872e-01,  8.63571525e-01],\n",
       "         [ 1.16618180e+00,  8.53030384e-01,  4.90255773e-01,\n",
       "           1.67203617e+00, -3.61783445e-01,  3.73628080e-01],\n",
       "         [-3.61589193e-02,  4.27917808e-01,  1.37576744e-01,\n",
       "           3.36276817e+00,  1.02947664e+00, -2.20988318e-01],\n",
       "         [-3.61589193e-02,  4.27917808e-01,  1.37576744e-01,\n",
       "           3.36276817e+00,  1.02947664e+00, -2.20988318e-01]],\n",
       "\n",
       "        [[ 1.62895906e+00,  1.18040729e+00,  4.68134463e-01,\n",
       "           1.82502747e+00, -1.43950656e-01,  7.50637293e-01],\n",
       "         [ 2.87408400e+00,  1.45809090e+00,  4.03944999e-01,\n",
       "           2.52108246e-01, -5.15189767e-01,  5.71866453e-01],\n",
       "         [ 2.22282147e+00,  1.85996556e+00,  4.34838980e-01,\n",
       "           9.15192127e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 2.11722159e+00,  1.16763413e+00,  6.60423696e-01,\n",
       "           1.03954840e+00, -2.47648686e-01,  3.78000289e-01],\n",
       "         [ 2.23766494e+00,  1.43697047e+00,  4.36299056e-01,\n",
       "           1.24654031e+00, -4.00235534e-01,  5.36996841e-01],\n",
       "         [ 6.28705919e-02,  3.67830992e-01,  8.05979073e-02,\n",
       "           3.51048923e+00,  8.77780855e-01, -2.68100441e-01],\n",
       "         [ 6.28705919e-02,  3.67830992e-01,  8.05979073e-02,\n",
       "           3.51048923e+00,  8.77780855e-01, -2.68100441e-01]],\n",
       "\n",
       "        [[ 8.73763442e-01,  7.91896522e-01,  6.21730566e-01,\n",
       "           1.50762594e+00,  2.15785399e-01,  6.30544901e-01],\n",
       "         [ 2.61549306e+00,  1.92864013e+00,  5.37556648e-01,\n",
       "           1.03936940e-01, -5.32173872e-01,  7.81592131e-01],\n",
       "         [ 2.00226712e+00,  2.20357585e+00,  5.06432652e-01,\n",
       "           8.33459049e-02, -2.47648686e-01,  2.84547329e-01],\n",
       "         [ 1.42168975e+00,  1.16877961e+00,  8.38789999e-01,\n",
       "           7.77228057e-01,  2.32560501e-01,  3.36050063e-01],\n",
       "         [ 1.37339139e+00,  1.11003160e+00,  5.41197240e-01,\n",
       "           5.77467084e-01, -4.73270267e-01,  5.37944078e-01],\n",
       "         [-3.71431917e-01,  2.20703959e-01,  2.70776033e-01,\n",
       "           2.73531437e+00,  1.01096439e+00, -1.31724983e-01],\n",
       "         [-3.71431917e-01,  2.20703959e-01,  2.70776033e-01,\n",
       "           2.73531437e+00,  1.01096439e+00, -1.31724983e-01]],\n",
       "\n",
       "        [[ 1.31420314e+00,  1.54708481e+00,  4.32116389e-01,\n",
       "          -3.75971198e-02, -1.41600370e-01,  9.51882303e-01],\n",
       "         [ 1.22503185e+00,  1.65405393e+00,  2.56409258e-01,\n",
       "           2.86611587e-01, -3.61783445e-01,  3.73628080e-01],\n",
       "         [ 2.05025959e+00,  2.18404746e+00,  4.11100566e-01,\n",
       "           6.93011135e-02, -4.00235534e-01,  4.76554096e-01],\n",
       "         [ 1.49153161e+00,  1.30787981e+00,  5.67220747e-01,\n",
       "           1.82174563e-01, -4.73270267e-01,  5.37944078e-01],\n",
       "         [ 6.83686256e-01,  9.86407757e-01,  4.75925863e-01,\n",
       "           5.88693559e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "         [-3.71431917e-01,  3.60543698e-01,  3.72120798e-01,\n",
       "           2.09463835e+00,  9.95682240e-01, -4.04672652e-01],\n",
       "         [-3.71431917e-01,  3.60543698e-01,  3.72120798e-01,\n",
       "           2.09463835e+00,  9.95682240e-01, -4.04672652e-01]],\n",
       "\n",
       "        [[-3.71431917e-01,  8.62884045e-01,  2.97588110e-03,\n",
       "           2.50352931e+00,  8.92349243e-01, -4.04672652e-01],\n",
       "         [ 4.35566634e-01,  1.91051495e+00,  2.97588110e-03,\n",
       "           8.61364007e-01,  1.83458984e-01, -4.04672652e-01],\n",
       "         [ 4.78931695e-01,  2.14543533e+00,  2.97588110e-03,\n",
       "           9.47688460e-01,  1.83458984e-01, -4.04672652e-01],\n",
       "         [ 1.35843009e-01,  1.37311125e+00,  7.04197511e-02,\n",
       "           1.61996794e+00,  4.24263805e-01, -4.04672652e-01],\n",
       "         [-2.92228758e-01,  9.87045288e-01,  2.97588110e-03,\n",
       "           1.95647383e+00,  5.45434713e-01, -4.04672652e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           2.19559684e-01,  4.81305905e-02,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           2.19559684e-01,  4.81305905e-02,  0.00000000e+00]],\n",
       "\n",
       "        [[-3.71431917e-01,  8.62884045e-01,  2.97588110e-03,\n",
       "           2.50352931e+00,  8.92349243e-01, -4.04672652e-01],\n",
       "         [ 4.35566634e-01,  1.91051495e+00,  2.97588110e-03,\n",
       "           8.61364007e-01,  1.83458984e-01, -4.04672652e-01],\n",
       "         [ 4.78931695e-01,  2.14543533e+00,  2.97588110e-03,\n",
       "           9.47688460e-01,  1.83458984e-01, -4.04672652e-01],\n",
       "         [ 1.35843009e-01,  1.37311125e+00,  7.04197511e-02,\n",
       "           1.61996794e+00,  4.24263805e-01, -4.04672652e-01],\n",
       "         [-2.92228758e-01,  9.87045288e-01,  2.97588110e-03,\n",
       "           1.95647383e+00,  5.45434713e-01, -4.04672652e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           2.19559684e-01,  4.81305905e-02,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           2.19559684e-01,  4.81305905e-02,  0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 8.62241864e-01,  1.28127015e+00,  4.99887228e-01,\n",
       "           4.89342093e-01,  5.61316192e-01,  1.72427073e-01],\n",
       "         [ 1.62044907e+00,  1.73900974e+00,  5.58682144e-01,\n",
       "           1.71492755e-01, -3.54618430e-01,  5.59220791e-01],\n",
       "         [ 1.65560472e+00,  1.60010290e+00,  4.66571718e-01,\n",
       "          -1.75995439e-01,  2.89281458e-03,  8.54269922e-01],\n",
       "         [ 1.66097701e+00,  1.98809814e+00,  3.56917948e-01,\n",
       "           7.00738430e-02, -1.78430557e-01,  3.81766915e-01],\n",
       "         [ 2.47064066e+00,  2.01599646e+00,  4.59761024e-01,\n",
       "          -2.50755370e-01, -3.50995399e-02,  1.04317105e+00],\n",
       "         [-3.71431917e-01,  3.99616629e-01,  4.19668913e-01,\n",
       "           2.18077135e+00,  1.47605240e+00, -4.04672652e-01],\n",
       "         [-3.71431917e-01,  3.99616629e-01,  4.19668913e-01,\n",
       "           2.18077135e+00,  1.47605240e+00, -4.04672652e-01]],\n",
       "\n",
       "        [[ 1.59004545e+00,  1.25036716e+00,  7.88359225e-01,\n",
       "           1.71492755e-01, -4.88293350e-01,  1.01225793e+00],\n",
       "         [ 1.45805168e+00,  8.74258757e-01,  1.05838275e+00,\n",
       "           7.18981862e-01,  4.49393898e-01,  7.37633049e-01],\n",
       "         [ 1.60293293e+00,  1.25158739e+00,  7.81524301e-01,\n",
       "           1.31295502e-01, -4.04800832e-01,  9.77974892e-01],\n",
       "         [ 1.67328501e+00,  1.42967010e+00,  7.13933945e-01,\n",
       "           2.44307518e-01, -4.26056743e-01,  6.03750885e-01],\n",
       "         [ 1.88827837e+00,  1.53678131e+00,  7.85459697e-01,\n",
       "           1.68571398e-01, -1.20723680e-01,  6.74548626e-01],\n",
       "         [-3.71431917e-01,  2.47547597e-01,  4.00192678e-01,\n",
       "           2.73390532e+00,  1.10188532e+00,  9.78730023e-02],\n",
       "         [-3.71431917e-01,  2.47547597e-01,  4.00192678e-01,\n",
       "           2.73390532e+00,  1.10188532e+00,  9.78730023e-02]],\n",
       "\n",
       "        [[ 1.65466905e+00,  1.57841134e+00,  4.74509031e-01,\n",
       "          -1.75995439e-01,  2.45702043e-02,  8.58192801e-01],\n",
       "         [ 1.63240075e+00,  1.70004535e+00,  5.59784591e-01,\n",
       "           1.31295502e-01, -1.85073063e-01,  5.26169717e-01],\n",
       "         [ 9.68928456e-01,  1.33688331e+00,  4.56968725e-01,\n",
       "           4.39041197e-01,  5.72584748e-01,  1.52836457e-01],\n",
       "         [ 1.95614815e+00,  1.99696374e+00,  4.81665134e-01,\n",
       "           1.35954142e-01, -5.05215645e-01,  5.89184523e-01],\n",
       "         [ 2.00192165e+00,  2.01639485e+00,  4.43445981e-01,\n",
       "          -1.14561744e-01,  3.41958672e-01,  5.42320907e-01],\n",
       "         [-3.71431917e-01,  3.78116578e-01,  3.79937321e-01,\n",
       "           2.25084066e+00,  1.47694254e+00, -4.04672652e-01],\n",
       "         [-3.71431917e-01,  3.78116578e-01,  3.79937321e-01,\n",
       "           2.25084066e+00,  1.47694254e+00, -4.04672652e-01]],\n",
       "\n",
       "        [[ 1.67606890e+00,  1.32445133e+00,  6.96522236e-01,\n",
       "           4.53726172e-01, -2.30857030e-01,  7.90259838e-01],\n",
       "         [ 1.71878052e+00,  1.04323649e+00,  8.23861241e-01,\n",
       "           6.09078050e-01, -2.00731486e-01,  5.56515694e-01],\n",
       "         [ 1.97217560e+00,  1.55132461e+00,  6.23591304e-01,\n",
       "           1.35954142e-01, -5.05215645e-01,  9.66519117e-01],\n",
       "         [ 1.76991105e+00,  1.17118788e+00,  6.73020244e-01,\n",
       "           3.96779716e-01,  3.11746001e-01,  4.36263055e-01],\n",
       "         [ 1.91676295e+00,  1.34231067e+00,  6.93020701e-01,\n",
       "           5.39139211e-01,  3.44469160e-01,  3.97525668e-01],\n",
       "         [-2.35384673e-01,  3.92695844e-01,  2.62475073e-01,\n",
       "           2.99675941e+00,  1.16014290e+00, -7.64296055e-02],\n",
       "         [-2.35384673e-01,  3.92695844e-01,  2.62475073e-01,\n",
       "           2.99675941e+00,  1.16014290e+00, -7.64296055e-02]],\n",
       "\n",
       "        [[ 2.43368602e+00,  1.76677477e+00,  7.16245592e-01,\n",
       "           2.19425261e-01, -6.82154819e-02,  1.46140969e+00],\n",
       "         [ 1.88172710e+00,  9.92426038e-01,  8.12267184e-01,\n",
       "           7.62384057e-01,  7.63241947e-02,  6.37059331e-01],\n",
       "         [ 1.96590281e+00,  1.37029409e+00,  6.91993296e-01,\n",
       "           6.62380874e-01,  2.10739315e-01,  9.56636667e-01],\n",
       "         [ 1.86471653e+00,  1.22911024e+00,  6.09900951e-01,\n",
       "           7.09801435e-01,  2.87353694e-01,  4.07271504e-01],\n",
       "         [ 2.14003062e+00,  1.34576237e+00,  6.78637385e-01,\n",
       "           4.28557903e-01,  5.61928034e-01,  5.32768250e-01],\n",
       "         [-7.63481259e-02,  3.35579455e-01,  2.23723754e-01,\n",
       "           3.27046204e+00,  1.25667620e+00, -2.33040750e-02],\n",
       "         [-7.63481259e-02,  3.35579455e-01,  2.23723754e-01,\n",
       "           3.27046204e+00,  1.25667620e+00, -2.33040750e-02]],\n",
       "\n",
       "        [[-1.22012094e-01,  1.03597486e+00,  2.97588110e-03,\n",
       "           1.79046607e+00,  6.03869081e-01, -4.04672652e-01],\n",
       "         [ 1.91094667e-01,  1.32323575e+00,  9.53977332e-02,\n",
       "           1.60464752e+00,  5.50176263e-01, -4.04672652e-01],\n",
       "         [-6.82009161e-02,  1.07918167e+00,  2.97588110e-03,\n",
       "           1.68118954e+00,  5.57275951e-01, -4.04672652e-01],\n",
       "         [ 3.24276537e-01,  1.54667759e+00,  2.97588110e-03,\n",
       "           1.08984208e+00,  3.54270697e-01, -4.04672652e-01],\n",
       "         [ 5.35359502e-01,  1.74794853e+00,  2.97588110e-03,\n",
       "           1.18705320e+00,  5.07919431e-01, -4.04672652e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.68075919e-01,  2.90557947e-02,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.68075919e-01,  2.90557947e-02,  0.00000000e+00]],\n",
       "\n",
       "        [[-1.22012094e-01,  1.03597486e+00,  2.97588110e-03,\n",
       "           1.79046607e+00,  6.03869081e-01, -4.04672652e-01],\n",
       "         [ 1.91094667e-01,  1.32323575e+00,  9.53977332e-02,\n",
       "           1.60464752e+00,  5.50176263e-01, -4.04672652e-01],\n",
       "         [-6.82009161e-02,  1.07918167e+00,  2.97588110e-03,\n",
       "           1.68118954e+00,  5.57275951e-01, -4.04672652e-01],\n",
       "         [ 3.24276537e-01,  1.54667759e+00,  2.97588110e-03,\n",
       "           1.08984208e+00,  3.54270697e-01, -4.04672652e-01],\n",
       "         [ 5.35359502e-01,  1.74794853e+00,  2.97588110e-03,\n",
       "           1.18705320e+00,  5.07919431e-01, -4.04672652e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.68075919e-01,  2.90557947e-02,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.68075919e-01,  2.90557947e-02,  0.00000000e+00]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modules: Decoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = AttentionDecoder(units, aggregation_graph='mean', n_heads=3)\n",
    "makespan, ll, pi = model(embedded_inputs)\n",
    "pi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# All together"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_instances = 640\n",
    "instance_size = (2, 8)\n",
    "batch_size = 64\n",
    "units = 64  # embedding dims\n",
    "layers = 2\n",
    "\n",
    "dataset = make_sparse_data(n_instances, msp_size=instance_size, random_state=2021)\n",
    "batch_dataset = dataset.batch(batch_size)\n",
    "inputs = list(batch_dataset.take(1))[0]\n",
    "\n",
    "ecoder_model = GGCNEncoder(units, layers)\n",
    "embedded_inputs = ecoder_model(inputs)\n",
    "\n",
    "n_heads = 8\n",
    "model = AttentionDecoder(units, aggregation_graph='mean', n_heads=n_heads)\n",
    "makespan, ll, pi = model(embedded_inputs)\n",
    "pi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inputs.adj_matrix[0]\n",
    "\n",
    "\n",
    "tf.math.reduce_all(tf.math.equal(inputs.adj_matrix[1], inputs.adj_matrix[2]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "print(inputs.adj_matrix[0].numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(inputs.adj_matrix[7].numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "from tensorflow import Tensor\n",
    "\n",
    "class MSPState:\n",
    "\n",
    "    def __init__(self, inputs):\n",
    "        \"\"\" \"\"\"\n",
    "        self.adj_matrix = inputs.adj_matrix\n",
    "        self.node_embed = inputs.node_embed\n",
    "        \n",
    "        batch_size, num_nodes, node_embed_dims = self.node_embed.shape\n",
    "        \n",
    "        self._first_node = tf.zeros((batch_size,1), dtype=tf.int64)\n",
    "        self._last_node = self._first_node\n",
    "        self._visited = tf.zeros((batch_size,1,num_nodes), dtype=tf.int64)\n",
    "        self._makespan = tf.zeros((batch_size,1))\n",
    "\n",
    "        self.i = tf.zeros(1, dtype=tf.int64) # # Vector with length num_steps\n",
    "        self.ids = tf.range(5, delta=1, dtype=tf.int64)[:, None] #  # Add steps dimension\n",
    "        #self._step_num = tf.zeros(1, dtype=tf.int64)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def first_node(self):\n",
    "        return self._first_node\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        # self._node_embed = None\n",
    "        # self._edge_embed = None\n",
    "        # self._adj_matrix = None\n",
    "        # self._first_job = None\n",
    "        # self._last_job = None\n",
    "\n",
    "    # @property\n",
    "    # def node_embed(self):\n",
    "    #     return self._node_embed\n",
    "\n",
    "    # @node_embed.setter\n",
    "    # def node_embed(self, node_embed):\n",
    "    #     self._node_embed = node_embed\n",
    "\n",
    "    # @property\n",
    "    # def adj_matrix(self):\n",
    "    #     return self._adj_matrix\n",
    "\n",
    "    # @adj_matrix.setter\n",
    "    # def adj_matrix(self, adj_matrix):\n",
    "    #     self._adj_matrix = adj_matrix\n",
    "\n",
    "    # def initialize(self, inputs):\n",
    "    #     self.adj_matrix = inputs.adj_matrix\n",
    "    #    return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MSPSolution:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # sequence: Tensor\n",
    "    # makespan: Tensor\n",
    "    # a: int"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "torch.arange(5, dtype=torch.int64)[:, None], tf.range(5, delta=1, dtype=tf.int64)[:, None]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MSPSparseGraph2(NamedTuple):\n",
    "    \"\"\" \"\"\"\n",
    "    adj_matrix: Tensor\n",
    "    node_features: Tensor\n",
    "    edge_features: Tensor\n",
    "    alpha: Tensor\n",
    "\n",
    "    @property\n",
    "    def num_node(self):\n",
    "        return self.adj_matrix.shape[-2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "class A(NamedTuple):\n",
    "\n",
    "    a: int\n",
    "\n",
    "    @property\n",
    "    def num(self):\n",
    "        return self.a\n",
    "\n",
    "    # jane._replace(a=26)\n",
    "\n",
    "\n",
    "class C(\n",
    "    NamedTuple(\n",
    "        'SSSSS',\n",
    "        A._field_types.items()\n",
    "    ),\n",
    "    A\n",
    "):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "class B(\n",
    "    NamedTuple(\n",
    "        'SSSB',\n",
    "        [\n",
    "            *A._field_types.items(),\n",
    "            ('weight', int)\n",
    "        ]\n",
    "    ),\n",
    "    A\n",
    "):\n",
    "    @property\n",
    "    def h(self):\n",
    "        return self.weight\n",
    "\n",
    "\n",
    "# class B(namedtuple('SSSB', [*A._fields, \"weight\"]), A):\n",
    "#     #[*A._fields, \"weight\"]\n",
    "\n",
    "#     @property\n",
    "#     def h(self):\n",
    "#         return self.weight\n",
    "\n",
    "    \n",
    "\n",
    "    # def __getitem__(self, key):\n",
    "    #     return self[key]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#B(A(a=90)._asdict(), weight=90)\n",
    "#B(**A(a=9090)._asdict(), weight=90).num\n",
    "#Ba = 2343, weight=23).num\n",
    "#dir(B)\n",
    "#C(a=90)\n",
    "B(*(34,), weight=34)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(A._field_types.items())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "A._field_types"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def fun(a):\n",
    "    print(a)\n",
    "\n",
    "fun(**inputs._asdict())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "[*A._field_types, ('v','d')]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for attr, val in inputs._asdict().items():\n",
    "#     print(attr, val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from typing import NamedTuple\n",
    "class AttentionModelFixed(NamedTuple):\n",
    "    \"\"\"\n",
    "    Context for AttentionModel decoder that is fixed during decoding so can be precomputed/cached\n",
    "    This class allows for efficient indexing of multiple Tensors at once\n",
    "    \"\"\"\n",
    "    node_embeddings: torch.Tensor\n",
    "    context_node_projected: torch.Tensor\n",
    "    glimpse_key: torch.Tensor\n",
    "    glimpse_val: torch.Tensor\n",
    "    logit_key: torch.Tensor\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if tf.is_tensor(key) or isinstance(key, slice):\n",
    "            return AttentionModelFixed(\n",
    "                node_embeddings=self.node_embeddings[key],\n",
    "                context_node_projected=self.context_node_projected[key],\n",
    "                glimpse_key=self.glimpse_key[:, key],  # dim 0 are the heads\n",
    "                glimpse_val=self.glimpse_val[:, key],  # dim 0 are the heads\n",
    "                logit_key=self.logit_key[key]\n",
    "            )\n",
    "        return super(AttentionModelFixed, self).__getitem__(key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from msp.layers import GGCNLayer\n",
    "from msp.graphs import MSPSparseGraph\n",
    "from msp.solutions import MSPState\n",
    "\n",
    "class AttentionDecoder(Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 units,\n",
    "                 *args, \n",
    "                 activation='relu',\n",
    "                 aggregation_graph='mean',\n",
    "                 n_heads=2, # make it 8\n",
    "                 mask_inner=True,\n",
    "                 tanh_clipping=10,\n",
    "                 decode_type='sampling',\n",
    "                 extra_logging=False,\n",
    "                 **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        super(AttentionDecoder, self).__init__(*args, **kwargs)\n",
    "        self.aggregation_graph = aggregation_graph\n",
    "        self.n_heads = n_heads\n",
    "        self.mask_inner = mask_inner\n",
    "        self.tanh_clipping = tanh_clipping\n",
    "        self.decode_type = decode_type\n",
    "        self.extra_logging = extra_logging\n",
    "\n",
    "        embedding_dim = units\n",
    "        \n",
    "        self.W_placeholder = self.add_weight(shape=(2*embedding_dim,),\n",
    "                                initializer='random_uniform', #Placeholder should be in range of activations (think)\n",
    "                                name='W_placeholder',\n",
    "                                trainable=True)\n",
    "\n",
    "        graph_embed_shape = tf.TensorShape((None, units))\n",
    "        self.fixed_context_layer = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.fixed_context_layer.build(graph_embed_shape)\n",
    "\n",
    "        # For each node we compute (glimpse key, glimpse value, logit key) so 3 * embedding_dim\n",
    "        project_node_embeddings_shape = tf.TensorShape((None, None, None, units))\n",
    "        self.project_node_embeddings = tf.keras.layers.Dense(3*units, use_bias=False)\n",
    "        self.project_node_embeddings.build(project_node_embeddings_shape)\n",
    "\n",
    "        #\n",
    "        # Embedding of first and last node\n",
    "        step_context_dim = 2*units\n",
    "        project_step_context_shape = tf.TensorShape((None, None, step_context_dim))\n",
    "        self.project_step_context = tf.keras.layers.Dense(embedding_dim, use_bias=False)\n",
    "        self.project_step_context.build(project_step_context_shape)\n",
    "\n",
    "        assert embedding_dim % n_heads == 0\n",
    "        # Note n_heads * val_dim == embedding_dim so input to project_out is embedding_dim\n",
    "\n",
    "        project_out_shape = tf.TensorShape((None, None, 1, embedding_dim))\n",
    "        self.project_out = tf.keras.layers.Dense(embedding_dim, use_bias=False)\n",
    "        self.project_out.build(project_out_shape)\n",
    "\n",
    "\n",
    "        # self.context_layer = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        # self.mha_layer = None\n",
    "        \n",
    "\n",
    "        # dynamic router\n",
    "\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=False, return_pi=False):\n",
    "        \"\"\" \"\"\"\n",
    "        state = MSPState(inputs)\n",
    "\n",
    "        node_embedding = inputs.node_embed\n",
    "\n",
    "        # AttentionModelFixed(node_embedding, fixed_context, *fixed_attention_node_data)\n",
    "        fixed = self._precompute(node_embedding)\n",
    "\n",
    "\n",
    "        # for i in range(num_steps):\n",
    "            # i == 0 should be machine \n",
    "            # AttentionCell(inputs, states)\n",
    "\n",
    "        outputs = []\n",
    "        sequences = []\n",
    "\n",
    "        # i = 0\n",
    "        while not state.all_finished():\n",
    "            # B x 1 x V\n",
    "            # Get log probabilities of next action\n",
    "            log_p, mask = self._get_log_p(fixed, state)\n",
    "            \n",
    "            selected = self._select_node(\n",
    "                    tf.squeeze(tf.exp(log_p), axis=-2), tf.squeeze(mask, axis=-2)) # Squeeze out steps dimension\n",
    "\n",
    "            state.update(selected)\n",
    "\n",
    "            outputs.append(log_p[:, 0, :])\n",
    "            sequences.append(selected)\n",
    "            \n",
    "            # if i == 1:\n",
    "            #     break\n",
    "            # i+=1\n",
    "        \n",
    "        _log_p, pi = tf.stack(outputs, axis=1), tf.stack(sequences, axis=1)\n",
    "\n",
    "        if self.extra_logging:\n",
    "            self.log_p_batch = _log_p\n",
    "            self.log_p_sel_batch = tf.gather(tf.squeeze(_log_p,axis=-2), pi, batch_dims=1)\n",
    "\n",
    "        # # Get predicted costs\n",
    "        # cost, mask = self.problem.get_costs(nodes, pi)\n",
    "        mask = None\n",
    "\n",
    "        ###################################################\n",
    "        # Need Clarity #############################################################\n",
    "        # loglikelihood \n",
    "        ll = self._calc_log_likelihood(_log_p, pi, mask)\n",
    "\n",
    "        ## Just for checking\n",
    "        return_pi = True    \n",
    "        if return_pi:\n",
    "            return state.makespan, ll, pi\n",
    "\n",
    "        return state.makespan, ll\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def _precompute(self, node_embedding, num_steps=1):\n",
    "\n",
    "        graph_embed = self._get_graph_embed(node_embedding)\n",
    "\n",
    "        fixed_context = self.fixed_context_layer(graph_embed)\n",
    "        # fixed context = (batch_size, 1, embed_dim) to make broadcastable with parallel timesteps\n",
    "        fixed_context = tf.expand_dims(fixed_context, axis=-2)\n",
    "\n",
    "        glimpse_key_fixed, glimpse_val_fixed, logit_key_fixed  = tf.split(\n",
    "            self.project_node_embeddings(tf.expand_dims(node_embedding, axis=-3)),\n",
    "            num_or_size_splits=3,\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        # No need to rearrange key for logit as there is a single head\n",
    "        fixed_attention_node_data = (\n",
    "            self._make_heads(glimpse_key_fixed, num_steps),\n",
    "            self._make_heads(glimpse_val_fixed, num_steps),\n",
    "            logit_key_fixed\n",
    "        )\n",
    "        return AttentionModelFixed(node_embedding, fixed_context, *fixed_attention_node_data)\n",
    "\n",
    "    def _get_graph_embed(self, node_embedding):\n",
    "        \"\"\" \"\"\"\n",
    "        if self.aggregation_graph == \"sum\":\n",
    "            graph_embed = tf.reduce_sum(node_embedding, axis=-2)\n",
    "        elif self.aggregation_graph == \"max\":\n",
    "            graph_embed = tf.reduce_max(node_embedding, axis=-2)\n",
    "        elif self.aggregation_graph == \"mean\":\n",
    "            graph_embed = tf.reduce_mean(node_embedding, axis=-2)\n",
    "        else:  # Default: dissable graph embedding\n",
    "            graph_embed = tf.reduce_sum(node_embedding, axis=-2) * 0.0\n",
    "\n",
    "        return graph_embed\n",
    "\n",
    "    def _make_heads(self, v, num_steps=None):\n",
    "\n",
    "        assert num_steps is None or v.shape[1] == 1 or v.shape[1] == num_steps\n",
    "        batch_size, _, num_nodes, embed_dims = v.shape\n",
    "        num_steps = num_steps if num_steps else 1\n",
    "        head_dims = embed_dims//self.n_heads\n",
    "\n",
    "        # M x B x N x V x (H/M)\n",
    "        return tf.transpose(\n",
    "            tf.broadcast_to(\n",
    "                tf.reshape(v, shape=[batch_size, v.shape[1], num_nodes, self.n_heads, head_dims]),\n",
    "                shape=[batch_size, num_steps, num_nodes, self.n_heads, head_dims]\n",
    "            ),\n",
    "            perm=[3, 0, 1, 2, 4]\n",
    "        )\n",
    "\n",
    "    def _get_log_p(self, fixed, state, normalize=True):\n",
    "        # Compute query = context node embedding\n",
    "        \n",
    "        # B x 1 x H\n",
    "        query = fixed.context_node_projected + \\\n",
    "                self.project_step_context(self._get_parallel_step_context(fixed.node_embeddings, state))\n",
    "        \n",
    "        # Compute keys and values for the nodes\n",
    "        glimpse_K, glimpse_V, logit_K = self._get_attention_node_data(fixed, state)\n",
    "\n",
    "        # Compute the mask, for masking next action based on previous actions\n",
    "        mask = state.get_mask()\n",
    "        graph_mask = state.get_graph_mask()\n",
    "\n",
    "        # Compute logits (unnormalized log_p)\n",
    "        log_p, glimpse = self._one_to_many_logits(query, glimpse_K, glimpse_V, logit_K, mask, graph_mask)\n",
    "\n",
    "        # [B x N x V]\n",
    "        # log-softmax activation function so that we get log probabilities over actions\n",
    "        if normalize:\n",
    "            log_p = tf.nn.log_softmax(log_p/1.0, axis=-1)\n",
    "\n",
    "        assert not tf.reduce_any(tf.math.is_nan(log_p)), \"Log probabilities over the nodes should be defined\"\n",
    "\n",
    "        return log_p, mask\n",
    "\n",
    "\n",
    "    def _get_parallel_step_context(self, node_embedding, state, from_depot=False):\n",
    "        \"\"\"\n",
    "        Returns the context per step, optionally for multiple steps at once \n",
    "        (for efficient evaluation of the model)\n",
    "        \"\"\"\n",
    "        # last_node at time t\n",
    "        last_node = state.get_current_node()\n",
    "        batch_size, num_steps = last_node.shape\n",
    "\n",
    "        if num_steps == 1:  # We need to special case if we have only 1 step, may be the first or not\n",
    "            if state.i.numpy()[0] == 0:\n",
    "                # First and only step, ignore prev_a (this is a placeholder)\n",
    "                # B x 1 x 2H\n",
    "                return tf.broadcast_to(self.W_placeholder[None, None, :], \n",
    "                                       shape=[batch_size, 1, self.W_placeholder.shape[-1]])\n",
    "            else:\n",
    "                return tf.concat(\n",
    "                    [\n",
    "                        tf.gather(node_embedding,state.first_node,batch_dims=1), \n",
    "                        tf.gather(node_embedding,last_node,batch_dims=1)  \n",
    "                    ],\n",
    "                    axis=-1\n",
    "                )\n",
    "                \n",
    "                # print('$'*20)\n",
    "                # node_embedding = torch.from_numpy(node_embedding.numpy())\n",
    "                # f = torch.from_numpy(state.first_node.numpy())\n",
    "                # l = torch.from_numpy(state.last_node.numpy())\n",
    "                # GG = node_embedding\\\n",
    "                # .gather(\n",
    "                #     1,\n",
    "                #     torch.cat((f, l), 1)[:, :, None].expand(batch_size, 2, node_embedding.size(-1))\n",
    "                # ).view(batch_size, 1, -1)\n",
    "                # print(GG)\n",
    "                # print('$'*20)\n",
    "                # ##############################################\n",
    "                # # PENDING\n",
    "                # ##############################################\n",
    "                # pass\n",
    "\n",
    "    def _get_attention_node_data(self, fixed, state):\n",
    "        return fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key\n",
    "\n",
    "    def _one_to_many_logits(self, query, glimpse_K, glimpse_V, logit_K, mask, graph_mask=None):\n",
    "        batch_size, num_steps, embed_dim = query.shape\n",
    "        query_size = key_size = val_size = embed_dim // self.n_heads\n",
    "\n",
    "        # M x B x N x 1 x (H/M)\n",
    "        # Compute the glimpse, rearrange dimensions to (n_heads, batch_size, num_steps, 1, key_size)\n",
    "        glimpse_Q = tf.transpose(\n",
    "            tf.reshape(\n",
    "                query, # B x 1 x H\n",
    "                shape=[batch_size, num_steps, self.n_heads, 1, query_size]\n",
    "            ),\n",
    "            perm=[2, 0, 1, 3, 4]\n",
    "        )\n",
    "\n",
    "        # [M x B x N x 1 x (H/M)] X [M x B x N x (H/M) x V] = [M x B x N x 1 x V]\n",
    "        # Batch matrix multiplication to compute compatibilities (n_heads, batch_size, num_steps, graph_size)\n",
    "        compatibility = tf.matmul(glimpse_Q, tf.transpose(glimpse_K, [0,1,2,4,3])) / math.sqrt(query_size)\n",
    "        \n",
    "        mask_temp = tf.cast(tf.broadcast_to(mask[None, :, :, None, :], shape=compatibility.shape), dtype=tf.double)\n",
    "        compatibility = tf.cast(compatibility, dtype=tf.double) + (mask_temp * -1e9)\n",
    "\n",
    "        graph_mask_temp = tf.cast(tf.broadcast_to(graph_mask[None, :, :, None, :], shape=compatibility.shape), dtype=tf.double)\n",
    "        compatibility = tf.cast(compatibility, dtype=tf.double) + (graph_mask_temp * -1e9)\n",
    "\n",
    "        compatibility = tf.cast(compatibility, dtype=tf.float32)        \n",
    "\n",
    "        # compatibility[tf.broadcast_to(mask[None, :, :, None, :], shape=compatibility.shape)] = -1e10\n",
    "        # compatibility[tf.broadcast_to(graph_mask[None, :, :, None, :], shape=compatibility.shape)] = -1e10\n",
    "\n",
    "        # attention weights a(c,j): \n",
    "        attention_weights = tf.nn.softmax(compatibility, axis=-1)\n",
    "\n",
    "\n",
    "        # [M x B x N x 1 x V] x [M x B x N x V x (H/M)] = [M x B x N x 1 x (H/M)]\n",
    "        heads = tf.matmul(attention_weights, glimpse_V)\n",
    "       \n",
    "        # B x N x 1 x H\n",
    "        # Project to get glimpse/updated context node embedding (batch_size, num_steps, embedding_dim)\n",
    "        glimpse = self.project_out(\n",
    "            tf.reshape(\n",
    "                tf.transpose(heads, perm=[1, 2, 3, 0, 4]),\n",
    "                shape=[batch_size, num_steps, 1, self.n_heads*val_size]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # B x N x 1 x H\n",
    "        # Now projecting the glimpse is not needed since this can be absorbed into project_out\n",
    "        # final_Q = self.project_glimpse(glimpse)\n",
    "        final_Q = glimpse\n",
    "\n",
    "\n",
    "        # [B x N x 1 x H] x [B x 1 x H x V] = [B x N x 1 x V] --> [B x N x V] (Squeeze) \n",
    "        # Batch matrix multiplication to compute logits (batch_size, num_steps, graph_size)\n",
    "        # logits = 'compatibility'\n",
    "        logits = tf.squeeze(tf.matmul(final_Q, tf.transpose(logit_K, perm=[0,1,3,2])),\n",
    "                            axis=-2) / math.sqrt(final_Q.shape[-1])\n",
    "\n",
    "        logits = logits + ( tf.cast(graph_mask, dtype=tf.float32) * -1e9)\n",
    "        logits = tf.math.tanh(logits) * self.tanh_clipping\n",
    "        logits = logits + ( tf.cast(mask, dtype=tf.float32) * -1e9)\n",
    "\n",
    "        # logits[graph_mask] = -1e10 \n",
    "        # logits = torch.tanh(logits) * self.tanh_clipping\n",
    "        # logits[mask] = -1e10\n",
    "        \n",
    "        return logits, tf.squeeze(glimpse, axis=-2)\n",
    "\n",
    "    \n",
    "    def _select_node(self, probs, mask):\n",
    "        assert tf.reduce_all(probs == probs) == True, \"Probs should not contain any nans\"\n",
    "\n",
    "        if self.decode_type == \"greedy\":\n",
    "            selected = tf.math.argmax(probs, axis=1)\n",
    "            assert not tf.reduce_any(tf.cast(tf.gather_nd(mask, tf.expand_dims(selected, axis=-1), batch_dims=1), dtype=tf.bool)), \"Decode greedy: infeasible action has maximum probability\"\n",
    "\n",
    "        elif self.decode_type == \"sampling\":\n",
    "            dist = tfp.distributions.Multinomial(total_count=1, probs=probs)\n",
    "            selected = tf.argmax(dist.sample(), axis=1)\n",
    "\n",
    "            # Check if sampling went OK\n",
    "            while tf.reduce_any(tf.cast(tf.gather_nd(mask, tf.expand_dims(selected, axis=-1), batch_dims=1), dtype=tf.bool)):\n",
    "                print('Sampled bad values, resampling!')\n",
    "                selected = tf.argmax(dist.sample(), axis=1)\n",
    "\n",
    "        else:\n",
    "            assert False, \"Unknown decode type\"\n",
    "        return selected\n",
    "\n",
    "    \n",
    "    def _calc_log_likelihood(self, _log_p, a, mask):\n",
    "        \n",
    "        # Get log_p corresponding to selected actions\n",
    "        batch_size, steps_count = a.shape\n",
    "        indices = tf.concat([\n",
    "        tf.expand_dims(tf.broadcast_to(tf.range(steps_count, dtype=tf.int64), shape=a.shape), axis=-1),\n",
    "        tf.expand_dims(a, axis=-1)],\n",
    "        axis=-1\n",
    "        )\n",
    "        log_p = tf.gather_nd(_log_p, indices, batch_dims=1)\n",
    "        \n",
    "\n",
    "        # _log_p = torch.from_numpy(_log_p.numpy())\n",
    "        # a = torch.from_numpy(a.numpy())\n",
    "        # AA = _log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n",
    "        # print(AA)\n",
    "        # print(log_p)\n",
    "        # print('DONE')\n",
    "        \n",
    "\n",
    "        # Get log_p corresponding to selected actions\n",
    "        # log_p = tf.gather(tf.squeeze(_log_p,axis=-2), a, batch_dims=1) #_log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # Optional: mask out actions irrelevant to objective so they do not get reinforced\n",
    "        if mask is not None:\n",
    "            log_p[mask] = 0\n",
    "\n",
    "        # Why??????\n",
    "        # assert (log_p > -1000).data.all(), \"Logprobs should not be -inf, check sampling procedure!\"\n",
    "\n",
    "        # Calculate log_likelihood\n",
    "        return tf.reduce_sum(log_p, axis=1) # log_p.sum(1)\n",
    "\n",
    "       \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # x = tf.constant([[True,  True], [False, False]])\n",
    "# # assert not tf.reduce_any(x), \"asdf\"\n",
    "# tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "#     from_logits=True, reduction='none')([]).dtype"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# t = torch.tensor([[[2,3],[5,2]], [[6,1],[0,4]]])\n",
    "# indices = torch.tensor([[[0, 0]],[[0, 0]]])\n",
    "# torch.gather(t, 1, indices)\n",
    " \n",
    "# # t = tf.constant([[[2,3],[5,2]], [[6,1],[0,4]]])\n",
    "# # indices = tf.constant([[0,0,0]])\n",
    "# # tf.gather_nd(t, indices=indices).numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # #tf.gather_nd()\n",
    "# # t = tf.constant([[[1,0],[1,0]], [[0,1],[1,1]]])\n",
    "# # t = embedded_inputs.adj_matrix\n",
    "# # indices = tf.constant([[0], [0]])\n",
    "# # indices = tf.expand_dims(indices, axis=-1)\n",
    "\n",
    "# # ~tf.cast(tf.gather_nd(t, indices=indices, batch_dims=1), tf.bool)\n",
    "# a = tf.constant([-3.0,-1.0, 0.0,1.0,3.0], dtype = tf.float32)\n",
    "# b = tf.keras.activations.tanh(a) \n",
    "# c = tf.math.tanh(a)\n",
    "# b.numpy(), c.numpy()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = AttentionDecoder(6, aggregation_graph='mean', n_heads=3)\n",
    "makespan, ll, pi = model(embedded_inputs)\n",
    "pi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.range(4, dtype=tf.int64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "indices = [[[1, 0]], [[0, 1]]]\n",
    "params = [[['a0', 'b0'], ['c0', 'd0']],\n",
    "            [['a1', 'b1'], ['c1', 'd1']]]\n",
    "#output = [['c0'], ['b1']]\n",
    "tf.gather"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = tf.Tensor(\n",
    "[[[0,1]\n",
    "  [1,2]],\n",
    "\n",
    " [[0,0]\n",
    "#   [1 1]]], shape=(2, 2, 2), dtype=int64)\n",
    "# tf.Tensor(\n",
    "# [[[-1.0886807e+00 -1.2036482e+00 -1.0126851e+00]\n",
    "#   [-9.8199100e+00 -1.0000000e+09 -5.4357959e-05]]\n",
    "\n",
    "#  [[-5.4339290e-01 -1.6555539e+00 -1.4773605e+00]\n",
    "#   [-1.0000000e+09 -7.7492166e-01 -6.1755723e-01]]], shape=(2, 2, 3), dtype=float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embeddings.gather(\n",
    "                        1,\n",
    "                        torch.cat((state.first_a, current_node), 1)[:, :, None].expand(batch_size, 2, embeddings.size(-1))\n",
    "                    ).view(batch_size, 1, -1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_log_p, pi#tf.expand_dims(pi,axis=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_log_p\n",
    "\n",
    "tf.gather(tf.squeeze(_log_p,axis=-2), pi, batch_dims=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_log_p = torch.Tensor(_log_p.numpy())\n",
    "pi = torch.from_numpy(tf.cast(pi, dtype=tf.int64).numpy()) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "log_p = _log_p.gather(2, pi.unsqueeze(-1)).squeeze(-1)\n",
    "log_p.sum(1) \n",
    "log_p\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pi.unsqueeze(-1)\n",
    "# tf.cast(pi, dtype=tf.int64)\n",
    "_log_p"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# seq = [torch.Tensor(i.numpy()) for i in seq]\n",
    "# torch.stack(seq, 1)\n",
    "pi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "last_node = tf.constant([[0], [1]], dtype=tf.int64)\n",
    "\n",
    "cur_node = selected[:, tf.newaxis]\n",
    "cur_node #cur_node\n",
    "\n",
    "tf.gather_nd(\n",
    "tf.gather_nd(embedded_inputs.edge_features, tf.concat([last_node, cur_node], axis=1), batch_dims=1),\n",
    "tf.reshape(tf.range(2), shape=(2,1)), # feature_indexfor processing time\n",
    "batch_dims=0\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "A = tf.gather_nd(embedded_inputs.edge_features, tf.concat([last_node, cur_node], axis=1), batch_dims=1)[:,0:1]\n",
    "A"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.reshape(tf.range(2), shape=(2,1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedded_inputs.node_features[:,]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cur_node[:,tf.newaxis,:] #embedded_inputs.node_features[:, ]\n",
    "tf.gather_nd(embedded_inputs.edge_features, tf.concat([last_node, cur_node], axis=1), batch_dims=1)[:,0:1] + \\\n",
    "tf.gather_nd(embedded_inputs.node_features, cur_node, batch_dims=1)[:,0:1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cur_node\n",
    "\n",
    "tf.rank(tf.ones(30,10))\n",
    "\n",
    "t = tf.constant([[[1, 1, 1, 4], [2, 2, 2, 4]], [[3, 3, 3, 4], [4, 4, 4, 4]]])\n",
    "tf.rank(t)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_visited = tf.zeros((batch_size,1,3), dtype=tf.uint8)\n",
    "_visited"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cur_node #[:,:,None] #, tf.ones([2,1,1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.concat([tf.reshape(tf.range(2, dtype=tf.int64),cur_node.shape), cur_node], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_visited.dtype"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size, _, _ = _visited.shape\n",
    "tf.tensor_scatter_nd_update( \n",
    "    tf.squeeze(_visited, axis=-2),\n",
    "    tf.concat([tf.reshape(tf.range(batch_size, dtype=tf.int64),cur_node.shape), cur_node], axis=1),\n",
    "    tf.ones((batch_size,), dtype=_visited.dtype)\n",
    ")[:,tf.newaxis,:]\n",
    "    \n",
    "    \n",
    "    #_visited, cur_node[:,:,None], tf.ones([2,1,1], dtype=tf.uint8))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cur_node = selected[:, tf.newaxis]\n",
    "cur_node #cur_node\n",
    "\n",
    "tf.concat([cur_node, cur_node], axis=1)\n",
    "\n",
    "tf.gather_nd(\n",
    "tf.gather_nd(embedded_inputs.edge_features, tf.concat([cur_node, cur_node], axis=1), batch_dims=1),\n",
    "tf.zeros((2,1), dtype=tf.int32)\n",
    ")\n",
    "\n",
    "tf.gather_nd(embedded_inputs.edge_features, tf.concat([cur_node, cur_node], axis=1), batch_dims=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.zeros((2,), dtype=tf.int32)\n",
    "tf.range(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedded_inputs.edge_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "probs_ = tf.squeeze(tf.exp(log_p), axis=-2)\n",
    "tf.squeeze(mask, axis=-2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedded_inputs.node_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "probs = torch.Tensor(log_p.numpy()).exp()[:, 0, :]\n",
    "mask_ = torch.Tensor(mask.numpy())[:, 0, :]\n",
    "\n",
    "probs, probs.multinomial(1) #.squeeze(1)\n",
    "\n",
    "\n",
    "# _, selected = probs.max(1)\n",
    "# assert not mask_.gather(1, selected.unsqueeze(\n",
    "#                 -1)).data.any(), \"Decode greedy: infeasible action has maximum probability\"\n",
    "# mask_.gather(1, selected.unsqueeze(-1)) #.data.any()\n",
    "probs_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "probs.multinomial(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# p = [.2, .3, .5]\n",
    "# dist = tfp.distributions.Multinomial(total_count=1, probs=probs_)\n",
    "\n",
    "p = [[.1, .2, .7], [.3, .3, .4]]  # Shape [2, 3]\n",
    "\n",
    "dist = tfp.distributions.Multinomial(total_count=1, probs=probs_)\n",
    "selected = tf.argmax(dist.sample(), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "selected = tf.math.argmax(tf.squeeze(tf.exp(log_p), axis=-2), axis=1)\n",
    "\n",
    "assert not tf.reduce_any(tf.cast(tf.gather_nd(mask_, tf.expand_dims(selected, axis=-1), batch_dims=1), dtype=tf.bool)), \"Decode greedy: infeasible action has maximum probability\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.expand_dims(selected, axis=-1), mask_, "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "probs_\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.broadcast_to(mask[None, :, None, :, :], shape=compatibility.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "compatibility\n",
    "\n",
    "compatibility[graph_mask[None, :, :, None, :].expand_as(compatibility)] = -1e10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def _make_heads(v, num_steps=None):\n",
    "    assert num_steps is None or v.size(1) == 1 or v.size(1) == num_steps\n",
    "    n_heads = 2\n",
    "    return (\n",
    "        v.contiguous().view(v.size(0), v.size(1), v.size(2), n_heads, -1)\n",
    "        .expand(v.size(0), v.size(1) if num_steps is None else num_steps, v.size(2), n_heads, -1)\n",
    "        .permute(3, 0, 1, 2, 4)  # (n_heads, batch_size, num_steps, graph_size, head_dim)\n",
    "    )\n",
    "\n",
    "from torch import nn\n",
    "W_placeholder = nn.Parameter(torch.Tensor(2 * 6))\n",
    "W_placeholder[None, None, :].expand(2, 1, W_placeholder.size(-1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.ones((3,4)).dtype"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_make_heads2(A, num_steps=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_make_heads2(A, num_steps=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "A.shape\n",
    "tf.broadcast_to(A, tf.TensorShape([-1, 4, None, None]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.split(\n",
    "tf.matmul(tf.ones((5,3))[None,:,:], tf.ones((3,3*3))),\n",
    "3,\n",
    "axis=-1\n",
    "\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.matmul(tf.ones((5,3))[None,:,:], tf.ones((3,3*3)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "embeddings = torch.Tensor(embedded_inputs.node_features.numpy())\n",
    "\n",
    "torch.cat((state.first_a, current_node), 1)[:, :, None]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedded_inputs.node_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "W_placeholder = nn.Parameter(torch.Tensor(2 * 5))\n",
    "\n",
    "\n",
    "W_placeholder[None, None, :].expand(batch_size, 1, W_placeholder.size(-1)).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.constant(W_placeholder[None, None, :].detach().numpy()).shape[-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.broadcast_to?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "W_placeholder[None, None, :].shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.reduce_mean(embedded_inputs.node_features, axis=-2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.Tensor(embedded_inputs.node_features.numpy()).max(1)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedded_inputs.node_features.numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from msp.layers import GGCNLayer\n",
    "from msp.graphs import MSPSparseGraph\n",
    "from msp.solutions import MSPState\n",
    "\n",
    "class AttentionDecoder(Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 units,\n",
    "                 *args, \n",
    "                 activation='relu',\n",
    "                 aggregation_graph='mean',\n",
    "                 n_heads=8,\n",
    "                 **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        super(AttentionDecoder, self).__init__(*args, **kwargs)\n",
    "        self.aggregation_graph = aggregation_graph\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        embedding_dim = units\n",
    "        self.W_placeholder = self.add_weight(shape=(2*embedding_dim,),\n",
    "                                initializer='random_uniform', #Placeholder should be in range of activations (think)\n",
    "                                trainable=True)\n",
    "\n",
    "        graph_embed_shape = tf.TensorShape((None, units))\n",
    "        self.fixed_context_layer = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.fixed_context_layer.build(graph_embed_shape)\n",
    "\n",
    "        # For each node we compute (glimpse key, glimpse value, logit key) so 3 * embedding_dim\n",
    "        project_node_embeddings_shape = tf.TensorShape((None, None, None, units))\n",
    "        self.project_node_embeddings = tf.keras.layers.Dense(3*units, use_bias=False)\n",
    "        self.project_node_embeddings.build(project_node_embeddings_shape)\n",
    "\n",
    "        #\n",
    "        # Embedding of first and last node\n",
    "        step_context_dim = 2*units\n",
    "        project_step_context_shape = tf.TensorShape((None, None, step_context_dim))\n",
    "        self.project_step_context = tf.keras.layers.Dense(embedding_dim, use_bias=False)\n",
    "        self.project_step_context.build(project_step_context_shape)\n",
    "        \n",
    "        #nn.Linear(step_context_dim, embedding_dim, bias=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # self.context_layer = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        # self.mha_layer = None\n",
    "        \n",
    "\n",
    "        # dynamic router\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # self.initial_layer_1 = tf.keras.layers.Dense(units)\n",
    "        # self.initial_layer_2 = tf.keras.layers.Dense(units)\n",
    "        # self.ggcn_layers = [GGCNLayer(units, activation=activation)\n",
    "        #                     for _ in range(layers)]\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\" \"\"\"\n",
    "        state = MSPState(inputs)\n",
    "\n",
    "        node_embedding = inputs.node_embed\n",
    "\n",
    "        # AttentionModelFixed(node_embedding, fixed_context, *fixed_attention_node_data)\n",
    "        fixed = self._precompute(node_embedding)\n",
    "        return fixed \n",
    "\n",
    "        while not state.all_finished():\n",
    "\n",
    "            log_p, mask = self._get_log_p(fixed, state)\n",
    "\n",
    "        \n",
    "\n",
    "        node_embed = inputs.node_features\n",
    "        return self._get_parallel_step_context(node_embed)\n",
    "\n",
    "\n",
    "    def _precompute(self, node_embedding, num_steps=1):\n",
    "\n",
    "        graph_embed = self._get_graph_embed(node_embedding)\n",
    "\n",
    "        fixed_context = self.fixed_context_layer(graph_embed)\n",
    "        # fixed context = (batch_size, 1, embed_dim) to make broadcastable with parallel timesteps\n",
    "        fixed_context = tf.expand_dims(fixed_context, axis=-2)\n",
    "\n",
    "        glimpse_key_fixed, glimpse_val_fixed, logit_key_fixed  = tf.split(\n",
    "            self.project_node_embeddings(tf.expand_dims(node_embedding, axis=-3)),\n",
    "            num_or_size_splits=3,\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        return glimpse_key_fixed\n",
    "\n",
    "        # No need to rearrange key for logit as there is a single head\n",
    "        fixed_attention_node_data = (\n",
    "            self._make_heads(glimpse_key_fixed, num_steps),\n",
    "            self._make_heads(glimpse_val_fixed, num_steps),\n",
    "            logit_key_fixed\n",
    "        )\n",
    "        return AttentionModelFixed(node_embedding, fixed_context, *fixed_attention_node_data)\n",
    "\n",
    "    def _get_graph_embed(self, node_embedding):\n",
    "        \"\"\" \"\"\"\n",
    "        if self.aggregation_graph == \"sum\":\n",
    "            graph_embed = tf.reduce_sum(node_embedding, axis=-2)\n",
    "        elif self.aggregation_graph == \"max\":\n",
    "            graph_embed = tf.reduce_max(node_embedding, axis=-2)\n",
    "        elif self.aggregation_graph == \"mean\":\n",
    "            graph_embed = tf.reduce_mean(node_embedding, axis=-2)\n",
    "        else:  # Default: dissable graph embedding\n",
    "            graph_embed = tf.reduce_sum(node_embedding, axis=-2) * 0.0\n",
    "\n",
    "        return graph_embed\n",
    "\n",
    "    def _make_heads(self, v, num_steps=None):\n",
    "\n",
    "        assert num_steps is None or v.shape[1] == 1 or v.shape[1] == num_steps\n",
    "        \n",
    "        batch_size, _, num_nodes, embed_dims = v.shape\n",
    "        num_steps = num_steps if num_steps else 1\n",
    "\n",
    "        # M x B x N x V x H\n",
    "        return tf.broadcast_to(\n",
    "            tf.broadcast_to(v, shape=[batch_size, num_steps, num_nodes, embed_dims])[None,:,:,:,:],\n",
    "            shape=[self.n_heads, batch_size, num_steps, num_nodes, embed_dims]\n",
    "        )\n",
    "\n",
    "    def _get_log_p(self, fixed, state, normalize=True):\n",
    "        # Compute query = context node embedding\n",
    "        \n",
    "        # B x 1 x H\n",
    "        query = fixed.context_node_projected + \\\n",
    "                self.project_step_context(self._get_parallel_step_context(fixed.node_embeddings, state))\n",
    "        \n",
    "        # Compute keys and values for the nodes\n",
    "        glimpse_K, glimpse_V, logit_K = self._get_attention_node_data(fixed, state)\n",
    "\n",
    "        graph_mask = None\n",
    "        if self.mask_graph:\n",
    "            # Compute the graph mask, for masking next action based on graph structure \n",
    "            graph_mask = state.get_graph_mask()  # Pending...........................................\n",
    "\n",
    "        # Compute logits (unnormalized log_p)\n",
    "        log_p, glimpse = self._one_to_many_logits(query, glimpse_K, glimpse_V, logit_K, mask, graph_mask)\n",
    "        \n",
    "\n",
    "\n",
    "    def _get_parallel_step_context(self, node_embedding, state, from_depot=False):\n",
    "        \"\"\"\n",
    "        Returns the context per step, optionally for multiple steps at once \n",
    "        (for efficient evaluation of the model)\n",
    "        \"\"\"\n",
    "        current_node = state.get_current_node()\n",
    "        batch_size, num_steps = current_node.shape\n",
    "\n",
    "        if num_steps == 1:  # We need to special case if we have only 1 step, may be the first or not\n",
    "            if self.i.numpy()[0] == 0:\n",
    "                # First and only step, ignore prev_a (this is a placeholder)\n",
    "                # B x 1 x 2H\n",
    "                return tf.broadcast_to(self.W_placeholder[None, None, :], \n",
    "                                       shape=[batch_size, 1, self.W_placeholder.shape[-1]])\n",
    "                \n",
    "            # else:\n",
    "            #     return embeddings.gather(\n",
    "            #         1,\n",
    "            #         torch.cat((state.first_a, current_node), 1)[:, :, None].expand(batch_size, 2, embeddings.size(-1))\n",
    "            #     ).view(batch_size, 1, -1)\n",
    "\n",
    "    def _get_attention_node_data(self, fixed, state):\n",
    "        return fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key\n",
    "\n",
    "    def _one_to_many_logits(self, query, glimpse_K, glimpse_V, logit_K, mask, graph_mask=None):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.boolean_mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MSPSparseGraph._fields"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = make_sparse_data(4, msp_size=(1,2), random_state=2021)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "graph = list(dataset.take(1))[0]\n",
    "graph"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "indices= tf.cast(tf.transpose(\n",
    "    tf.concat([\n",
    "        edge_index,\n",
    "        tf.scatter_nd(\n",
    "            tf.constant([[1],[0]]),\n",
    "            edge_index,\n",
    "            edge_index.shape\n",
    "        )\n",
    "    ], axis=-1)\n",
    "), tf.int64)\n",
    "indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adj_matrix = tf.sparse.SparseTensor(\n",
    "    indices= indices,\n",
    "    values = tf.ones([2*edge_index.shape[-1]]),\n",
    "    dense_shape = [3,3]\n",
    ")\n",
    "adj_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.sparse.to_dense(tf.sparse.reorder(adj_matrix))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reorder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.ones([edge_index.shape[-1]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "E = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2], [2, 0]], values=[1, 2], dense_shape=[3, 4])\n",
    "tf.sparse.to_dense()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.ones((2,3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class GGCNLayer(Layer):\n",
    "\n",
    "    # @validate_hyperparams\n",
    "    def __init__(self, \n",
    "                 units,\n",
    "                 *args, \n",
    "                 activation='relu', \n",
    "                 use_bias=True, \n",
    "                 normalization='batch',\n",
    "                 aggregation='mean',\n",
    "                 **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        super(GGCNLayer, self).__init__(*args, **kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.normalization= normalization\n",
    "        self.aggregation = aggregation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Create the state of the layer (weights)\"\"\"\n",
    "        print('Build')\n",
    "        node_features_shape = input_shape.node_features\n",
    "        edge_featues_shape = input_shape.edge_features\n",
    "        embedded_shape = tf.TensorShape((None, self.units))\n",
    "\n",
    "        # _initial_projection_layer (think on it)\n",
    "\n",
    "        with tf.name_scope('node'):\n",
    "            with tf.name_scope('U'):\n",
    "                self.U = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.U.build(node_features_shape)\n",
    "\n",
    "            with tf.name_scope('V'):\n",
    "                self.V = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.V.build(node_features_shape)\n",
    "\n",
    "            with tf.name_scope('norm'):\n",
    "                self.norm_h = {\n",
    "                    \"batch\": tf.keras.layers.BatchNormalization(),\n",
    "                    \"layer\": tf.keras.layers.LayerNormalization()\n",
    "                }.get(self.normalization, None)\n",
    "                if self.norm_h:\n",
    "                    self.norm_h.build(embedded_shape)\n",
    "\n",
    "        with tf.name_scope('edge'):\n",
    "            with tf.name_scope('A'):\n",
    "                self.A = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.A.build(tf.TensorShape((None, node_features_shape[-1])))\n",
    "            \n",
    "            with tf.name_scope('B'):\n",
    "                self.B = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.B.build(node_features_shape)\n",
    "\n",
    "            with tf.name_scope('C'):\n",
    "                self.C = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "                self.C.build(edge_featues_shape)\n",
    "\n",
    "            with tf.name_scope('norm'):\n",
    "                self.norm_e = {\n",
    "                    'batch': tf.keras.layers.BatchNormalization(),\n",
    "                    'layer': tf.keras.layers.LayerNormalization(axis=-2)\n",
    "                }.get(self.normalization, None)\n",
    "                if self.norm_e:\n",
    "                    self.norm_e.build(embedded_shape)\n",
    "    \n",
    "        super().build(input_shape)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        \"\"\" \"\"\"\n",
    "        print('call')\n",
    "        adj_matrix = inputs.adj_matrix\n",
    "        h = inputs.node_features\n",
    "        e = inputs.edge_features\n",
    "\n",
    "        # Edges Featuers\n",
    "        Ah = self.A(h)\n",
    "        Bh = self.B(h)\n",
    "        Ce = self.C(e)\n",
    "        e = self._update_edges(e, [Ah, Bh, Ce])\n",
    "\n",
    "        edge_gates = tf.sigmoid(e)\n",
    "\n",
    "        # Nodes Features\n",
    "        Uh = self.U(h)\n",
    "        Vh = self.V(h)\n",
    "        h = self._update_nodes(\n",
    "            h,\n",
    "            [Uh, self._aggregate(Vh, edge_gates, adj_matrix)]\n",
    "        )\n",
    "\n",
    "        outputs = MSPSparseGraph(adj_matrix, h, e, inputs.alpha)\n",
    "        return inputs\n",
    "        \n",
    "    def _update_edges(self, e, transformations:list):\n",
    "        \"\"\"Update edges features\"\"\"\n",
    "        Ah, Bh, Ce  = transformations\n",
    "        e_new = tf.expand_dims(Ah, axis=1) + tf.expand_dims(Bh, axis=2) + Ce\n",
    "        # Normalization\n",
    "        batch_size, num_nodes, num_nodes, hidden_dim = e_new.shape\n",
    "        if self.norm_e:\n",
    "            e_new = tf.reshape(\n",
    "                self.norm_e(\n",
    "                    tf.reshape(e_new, [batch_size*num_nodes*num_nodes, hidden_dim])\n",
    "                ), e_new.shape\n",
    "            )\n",
    "        # Activation\n",
    "        e_new = self.activation(e_new)\n",
    "        # Skip/residual Connection\n",
    "        e_new = e + e_new\n",
    "        return e_new\n",
    "\n",
    "    def _update_nodes(self, h, transformations:list):\n",
    "        \"\"\" \"\"\"\n",
    "        Uh, aggregated_messages = transformations\n",
    "        h_new = tf.math.add_n([Uh, aggregated_messages])\n",
    "        # Normalization\n",
    "        batch_size, num_nodes, hidden_dim = h_new.shape\n",
    "        if self.norm_h:\n",
    "            h_new = tf.reshape(\n",
    "                self.norm_h(\n",
    "                    tf.reshape(h_new, [batch_size*num_nodes, hidden_dim])\n",
    "                ), h_new.shape\n",
    "            )\n",
    "        # Activation\n",
    "        h_new = self.activation(h_new)\n",
    "        # Skip/residual Connection\n",
    "        h_new = h + h_new\n",
    "        return h_new\n",
    "\n",
    "    def _aggregate(self, Vh, edge_gates, adj_matrix):\n",
    "        \"\"\" \"\"\"\n",
    "        # Reshape as edge_gates\n",
    "        Vh = tf.broadcast_to(\n",
    "            tf.expand_dims(Vh, axis=1),\n",
    "            edge_gates.shape\n",
    "        )\n",
    "        # Gating mechanism\n",
    "        Vh = edge_gates * Vh\n",
    "        \n",
    "        # Enforce graph structure\n",
    "        # mask = tf.broadcast_to(tf.expand_dims(adj_matrix,axis=-1), Vh.shape)\n",
    "        # Vh[~mask] = 0\n",
    "\n",
    "        # message aggregation\n",
    "        if self.aggregation == 'mean':\n",
    "            total_messages = tf.cast(\n",
    "                tf.expand_dims(\n",
    "                    tf.math.reduce_sum(adj_matrix, axis=-1),\n",
    "                    axis=-1\n",
    "                ),\n",
    "                Vh.dtype\n",
    "            )\n",
    "            return tf.math.reduce_sum(Vh, axis=2) / total_messages\n",
    "        \n",
    "        elif self.aggregation == 'sum':\n",
    "            return tf.math.reduce_sum(Vh, axis=2)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "B, V, H = 1, 3, 2\n",
    "h = tf.ones((B, V, H))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = make_sparse_data(4, msp_size=(1,2), random_state=2020)\n",
    "graphs = list(dataset.batch(2))\n",
    "VVh = list(graphs)[0].edge_features\n",
    "A = list(graphs)[0].adj_matrix\n",
    "VVh.shape, A.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mask = tf.cast(tf.broadcast_to(\n",
    "#     tf.expand_dims(A, axis=-1),\n",
    "#     VVh.shape\n",
    "# ), tf.bool)\n",
    "# VVh[~mask] \n",
    "ggcn.variables"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "units = graphs[0].edge_features.shape[-1]\n",
    "ggcn = GGCNLayer(units=units, use_bias=True, name='GGCN_Layer')\n",
    "output = ggcn(graphs[0])\n",
    "output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.cast(\n",
    "    tf.expand_dims(\n",
    "        tf.math.reduce_sum(list(graphs)[0].adj_matrix, axis=-1),\n",
    "        axis=-1\n",
    "    ),\n",
    "    Vh.dtype\n",
    ")\n",
    "    tf.expand_dims(\n",
    "    tf.math.reduce_sum(list(graphs)[0].adj_matrix, axis=-1),\n",
    "    axis=-1).dtype"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.math.reduce_max(graphs[0].edge_features, axis=-2 )[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(graphs)[0].adj_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ggcn = GGCNLayer(units=units, use_bias=True, name='GGCN_Layer')\n",
    "# output = ggcn(graphs[0])\n",
    "# output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "graphs = list(make_data(1, msp_size=(1,2), random_state=2021).take(1))[0]\n",
    "\n",
    "num_edges = 3\n",
    "\n",
    "\n",
    "A = tf.sparse.SparseTensor(\n",
    "    indices= tf.cast(tf.transpose(graphs['edge_index']), tf.int64),\n",
    "    values = tf.ones([num_edges]),\n",
    "    dense_shape = [3,3]\n",
    ")\n",
    "\n",
    "tf.sparse.to_dense(A)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.cast(tf.transpose(graphs['edge_index']), tf.int64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ggcn.variables\n",
    "tf.cast(tf.transpose(graphs['edge_index']), tf.int64)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "edge_index = tf.cast(tf.transpose(\n",
    "    tf.concat([\n",
    "        graphs['edge_index'],\n",
    "        tf.scatter_nd(\n",
    "            tf.constant([[1],[0]]),\n",
    "            graphs['edge_index'],\n",
    "            graphs['edge_index'].shape\n",
    "        )\n",
    "    ], axis=-1)\n",
    "), tf.int32)\n",
    "edge_index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = tf.keras.Sequential([\n",
    "    GGCNLayer(units=units, use_bias=True, name='GGCN_Layer')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "model.fit(dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}